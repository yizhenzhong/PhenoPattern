{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotyping pattern classification\n",
    "Yizhen Zhong\n",
    "03282018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenotyping algorithms are designed to enable robust selection of patients that meet certain research interests from the Electronic Health Record system. The development process of phenotyping algorithm is very time and resource intensive, which requires manual review of experts and multiple rounds of validation. Therefore, the automatic development of phenotyping algorithm with machine learning techniques is of great interest. Recently, the “phenotype design patterns” are proposed to extract the common and repeated concepts from phenotyping algorithms. With the understanding of how phenotyping algorithms are constructed from design patterns, it is potential to automate the algorithm development process. Here, I will explore the usage of the Convolution Neural Network to classify short sentence segments from phenotyping algorithms into design patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have obtained 160 sentences extracted from the phenotyping algorithms. 53 of them were classified as “Rule of N” and 107 were classified as other concepts. I first split the data into training and testing dataset and train a Convolution Neural Network on the training set and evaluate the best model on the testing set of its ability to classify “Rule of N” sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is modified from [https://github.com/dennybritz/cnn-text-classification-tf]\n",
    "* <span style=\"color:#a50e3e;\">Number of classes: 2 \n",
    "* <span style=\"color:#a50e3e;\">Word embedding dimension: [100, 200, 300, 400,  \n",
    "* <span style=\"color:#a50e3e;\">Filter size: [3,4,5] \n",
    "* <span style=\"color:#a50e3e;\">Filter number: 50\n",
    "* <span style=\"color:#a50e3e;\">Drop out rate: 0.5\n",
    "* <span style=\"color:#a50e3e;\">Batch size: 15\n",
    "* <span style=\"color:#a50e3e;\">Epoch number: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import _pickle as cPickle\n",
    "from text_cnn import TextCNN\n",
    "from tensorflow.contrib import learn\n",
    "import data_helpers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_f1(count_site):\n",
    "    #TP,FP,TN,FN\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    pre = []\n",
    "    recal = []\n",
    "    for lis in count_site:\n",
    "        TP = TP + lis[0]\n",
    "        FP = FP + lis[1]\n",
    "        FN = FN + lis[3]\n",
    "        if lis[0] + lis[1] == 0:\n",
    "            pre.append(0)\n",
    "        else:\n",
    "            pre.append(lis[0]/float((lis[0]+lis[1])))\n",
    "        recal.append(lis[0]/float((lis[0]+lis[3])))\n",
    "  \n",
    "    if TP + FP == 0:\n",
    "        micro_pres = 0\n",
    "    else:\n",
    "        micro_pres = float(TP)/(TP + FP)\n",
    "    #print micro_pres\n",
    "    micro_recall = float(TP)/(TP + FN)\n",
    "    #print micro_recall\n",
    "    f1 = 2*micro_pres*micro_recall/(micro_pres + micro_recall)\n",
    "    macro_pre = sum(pre)/len(count_site) \n",
    "    macro_recall = sum(recal)/len(count_site)\n",
    "    macro_f1 = 2*macro_pre*macro_recall/(macro_pre + macro_recall)\n",
    "    return macro_f1,f1\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    COUNT = []\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==0 and y_hat[i] == 1:\n",
    "           FP += 1\n",
    "    \n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "    \n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==1 and y_hat[i] == 0:\n",
    "           FN += 1\n",
    "    if TP == 0:\n",
    "        precision = 0\n",
    "        f1 = 0\n",
    "    else:\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return [TP,FP,TN,FN], f1\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a embedding size\n",
    "word2vec = \"embedding_mimic3_pp600_0829.pik\"\n",
    "f = cPickle.load(open(word2vec,\"rb\"),encoding='bytes')\n",
    "em,vocab_out,vocab_in = f[0],f[1],f[2]\n",
    "count_all = [] \n",
    "f1_all = []\n",
    "em_dim = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "name = [\"Confirm Disease Was Checked\",\"Rule of N\",\"Use Distinct Dates\",\"Credentials of the Actor\",\"Where Did It Happen?\",\"Check For Negation\"]#\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "#label_class = name[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  Confirm Disease Was Checked\n",
      "Vocabulary Size: 414\n",
      "Train/Test split: 91/40\n",
      "Train/Val split: 73/18\n",
      "Writing to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611\n",
      "\n",
      "Using pre-trained word2vec\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1000\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-1900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877611/checkpoints/model-2000\n",
      "\n",
      "runs/1522877611/checkpoints\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "\n",
      "Confirm Disease Was Checked\n",
      "Total number of test examples: 40\n",
      "F1: 0.285714\n",
      "[1, 0, 34, 5]\n",
      "[]\n",
      "[0.2857142857142857]\n",
      "processing:  Rule of N\n",
      "Vocabulary Size: 414\n",
      "Train/Test split: 91/40\n",
      "Train/Val split: 73/18\n",
      "Writing to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786\n",
      "\n",
      "Using pre-trained word2vec\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1000\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-1900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877786/checkpoints/model-2000\n",
      "\n",
      "runs/1522877786/checkpoints\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "\n",
      "Rule of N\n",
      "Total number of test examples: 40\n",
      "F1: 0.47619\n",
      "[5, 0, 24, 11]\n",
      "[[1, 0, 34, 5]]\n",
      "[0.2857142857142857, 0.47619047619047616]\n",
      "processing:  Use Distinct Dates\n",
      "Vocabulary Size: 414\n",
      "Train/Test split: 91/40\n",
      "Train/Val split: 73/18\n",
      "Writing to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966\n",
      "\n",
      "Using pre-trained word2vec\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-1900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522877966/checkpoints/model-2000\n",
      "\n",
      "runs/1522877966/checkpoints\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "\n",
      "Use Distinct Dates\n",
      "Total number of test examples: 40\n",
      "F1: 0.571429\n",
      "[4, 0, 30, 6]\n",
      "[[1, 0, 34, 5], [5, 0, 24, 11]]\n",
      "[0.2857142857142857, 0.47619047619047616, 0.5714285714285715]\n",
      "processing:  Credentials of the Actor\n",
      "Vocabulary Size: 414\n",
      "Train/Test split: 91/40\n",
      "Train/Val split: 73/18\n",
      "Writing to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145\n",
      "\n",
      "Using pre-trained word2vec\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1000\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-1900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878145/checkpoints/model-2000\n",
      "\n",
      "runs/1522878145/checkpoints\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "\n",
      "Credentials of the Actor\n",
      "Total number of test examples: 40\n",
      "F1: 0.888889\n",
      "[4, 1, 35, 0]\n",
      "[[1, 0, 34, 5], [5, 0, 24, 11], [4, 0, 30, 6]]\n",
      "[0.2857142857142857, 0.47619047619047616, 0.5714285714285715, 0.888888888888889]\n",
      "processing:  Where Did It Happen?\n",
      "Vocabulary Size: 414\n",
      "Train/Test split: 91/40\n",
      "Train/Val split: 73/18\n",
      "Writing to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322\n",
      "\n",
      "Using pre-trained word2vec\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1000\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-1900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878322/checkpoints/model-2000\n",
      "\n",
      "runs/1522878322/checkpoints\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where Did It Happen?\n",
      "Total number of test examples: 40\n",
      "F1: 0.444444\n",
      "[2, 0, 33, 5]\n",
      "[[1, 0, 34, 5], [5, 0, 24, 11], [4, 0, 30, 6], [4, 1, 35, 0]]\n",
      "[0.2857142857142857, 0.47619047619047616, 0.5714285714285715, 0.888888888888889, 0.4444444444444445]\n",
      "processing:  Check For Negation\n",
      "Vocabulary Size: 414\n",
      "Train/Test split: 91/40\n",
      "Train/Val split: 73/18\n",
      "Writing to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489\n",
      "\n",
      "Using pre-trained word2vec\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1000\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1100\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1200\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1300\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1400\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1500\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1600\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1700\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1800\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-1900\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "\n",
      "Saved model checkpoint to /Users/zhongyi/Box Sync/phenotype_patterns_data/PhenoPattern/venv/runs/1522878489/checkpoints/model-2000\n",
      "\n",
      "runs/1522878489/checkpoints\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "\n",
      "Check For Negation\n",
      "Total number of test examples: 40\n",
      "F1: 0.6\n",
      "[3, 1, 33, 3]\n",
      "[[1, 0, 34, 5], [5, 0, 24, 11], [4, 0, 30, 6], [4, 1, 35, 0], [2, 0, 33, 5]]\n",
      "[0.2857142857142857, 0.47619047619047616, 0.5714285714285715, 0.888888888888889, 0.4444444444444445, 0.6]\n"
     ]
    }
   ],
   "source": [
    "#################loop over each class\n",
    "for i in range(6):\n",
    "    label_class = name[i]\n",
    "\n",
    "    print(\"processing: \", label_class)\n",
    "    label = \"_\".join(label_class.split())\n",
    "    x_text, y = data_helpers.load_data_and_labels(\"./data/\" + label + \"_seed100replace_0403_train.txt\", \n",
    "                                                  \"./data/\" + label + \"_seed100replace_0403_train_rest.txt\")\n",
    "    x_test, y_test = data_helpers.load_data_and_labels(\"./data/\" + label + \"_seed100replace_0403_test.txt\",\n",
    "                                                      \"./data/\" + label + \"_seed100replace_0403_test_rest.txt\")\n",
    "\n",
    "\n",
    "    max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "    vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "    x = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "    x_test = np.array(list(vocab_processor.transform(x_test)))\n",
    "\n",
    "    dev_sample_percentage = 0.2\n",
    "    dev_sample_index = -1 * int(dev_sample_percentage * float(len(y)))\n",
    "    x_train, x_dev = x[:dev_sample_index], x[dev_sample_index:]\n",
    "    y_train, y_dev = y[:dev_sample_index], y[dev_sample_index:]\n",
    "\n",
    "\n",
    "    print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "    print(\"Train/Test split: {:d}/{:d}\".format(len(y), len(y_test)))\n",
    "    print(\"Train/Val split: {:d}/{:d}\".format(len(y_train), len(y_dev)))\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "          allow_soft_placement=True,\n",
    "          log_device_placement=False)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=em_dim,\n",
    "                filter_sizes=list(map(int, \"3,4,5\".split(\",\"))),\n",
    "                num_filters=50,\n",
    "                l2_reg_lambda=0)\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "            grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "            train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "            # Keep track of gradient values and sparsity (optional)\n",
    "            grad_summaries = []\n",
    "            for g, v in grads_and_vars:\n",
    "                if g is not None:\n",
    "                    grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                    sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                    grad_summaries.append(grad_hist_summary)\n",
    "                    grad_summaries.append(sparsity_summary)\n",
    "            grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "\n",
    "             # Output directory for models and summaries\n",
    "            timestamp = str(int(time.time()))\n",
    "            out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "            print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "            # Summaries for loss and accuracy\n",
    "            loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "            acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "\n",
    "            # Train Summaries\n",
    "            train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "            train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "            train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "\n",
    "            # Dev summaries\n",
    "            dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "            dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "            dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n",
    "\n",
    "\n",
    "            # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=5)\n",
    "\n",
    "\n",
    "            # Write vocabulary\n",
    "            vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "            # Initialize all variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            initW = np.random.uniform(-0.25,-0.25,(len(vocab_processor.vocabulary_),em_dim))\n",
    "\n",
    "            for word in vocab_in:\n",
    "                idx = vocab_processor.vocabulary_.get(word.decode(\"utf-8\"))\n",
    "                initW[idx] = em[vocab_in[word],]\n",
    "\n",
    "\n",
    "            sess.run(cnn.W.assign(initW))\n",
    "            print(\"Using pre-trained word2vec\")\n",
    "            #print(sess.run(cnn.W[6,]))\n",
    "            def train_step(x_batch, y_batch):\n",
    "                \"\"\"\n",
    "                A single training step\n",
    "                \"\"\"\n",
    "                feed_dict = {\n",
    "                  cnn.input_x: x_batch,\n",
    "                  cnn.input_y: y_batch,\n",
    "                  cnn.dropout_keep_prob: 0.5\n",
    "                }\n",
    "                _, step, summaries, loss, accuracy = sess.run(\n",
    "                    [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],\n",
    "                    feed_dict)\n",
    "                time_str = datetime.datetime.now().isoformat()\n",
    "                #print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "                train_summary_writer.add_summary(summaries, step)\n",
    "                return [time_str, step, loss, accuracy]\n",
    "             # Generate batches\n",
    "\n",
    "            def dev_step(x_batch, y_batch, writer=None):\n",
    "                \"\"\"\n",
    "                Evaluates model on a dev set\n",
    "                \"\"\"\n",
    "                feed_dict = {\n",
    "                  cnn.input_x: x_batch,\n",
    "                  cnn.input_y: y_batch,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "                step, summaries, loss, accuracy = sess.run(\n",
    "                    [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n",
    "                    feed_dict)\n",
    "                time_str = datetime.datetime.now().isoformat()\n",
    "                #print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "                if writer:\n",
    "                    writer.add_summary(summaries, step)\n",
    "                return [time_str, step, loss, accuracy]    \n",
    "\n",
    "            batches = data_helpers.batch_iter(list(zip(x, y)), 10, 200)   \n",
    "            # Training loop. For each batch...\n",
    "            #best_perf = [0,0,0,0]\n",
    "            loss_history = []\n",
    "            for batch in batches:\n",
    "                x_batch, y_batch = zip(*batch)\n",
    "                train_step(x_batch, y_batch)\n",
    "                current_step = tf.train.global_step(sess, global_step)\n",
    "                if current_step % 100 == 0:\n",
    "                    print(\"\\nEvaluation:\")\n",
    "                    dev_step(x_dev, y_dev, writer=dev_summary_writer)\n",
    "                    print(\"\")\n",
    "                if current_step % 100 == 0:\n",
    "                    path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                    print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "\n",
    "\n",
    "            #test = dev_step(x_test_transform, y_test,writer=dev_summary_writer)\n",
    "            #print(\"{}: step {}, loss {:g}, acc {:g}\".format(test[0],test[1],test[2],test[3]))\n",
    "\n",
    "\n",
    "    checkpoint_dir = out_dir[66:] + \"/checkpoints\"\n",
    "    print(checkpoint_dir)\n",
    "\n",
    "    print(\"\\nEvaluating...\\n\")\n",
    "    # Evaluation\n",
    "    # ==================================================\n",
    "    print()\n",
    "    checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "          allow_soft_placement=True,\n",
    "          log_device_placement=True)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            # Load the saved meta graph and restore variables\n",
    "            saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "            saver.restore(sess, checkpoint_file)\n",
    "\n",
    "            # Get the placeholders from the graph by name\n",
    "            input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "            # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "            dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "\n",
    "            # Tensors we want to evaluate\n",
    "            predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "            # Generate batches for one epoch\n",
    "            batches = data_helpers.batch_iter(list(x_test), 20, 1, shuffle=False)\n",
    "\n",
    "            # Collect the predictions here\n",
    "            all_predictions = []\n",
    "\n",
    "            for x_test_batch in batches:\n",
    "                batch_predictions = sess.run(predictions, {input_x: x_test_batch, dropout_keep_prob: 1.0})\n",
    "                all_predictions = np.concatenate([all_predictions, batch_predictions])\n",
    "\n",
    "    print(name[i])\n",
    "    y_test_label = np.argmax(y_test, axis=1)\n",
    "    if y_test is not None:\n",
    "        correct_predictions = float(sum(all_predictions == y_test_label))\n",
    "        print(\"Total number of test examples: {}\".format(len(y_test_label))) \n",
    "        count, f1 = perf_measure(y_test_label, all_predictions)\n",
    "        print(\"F1: {:g}\".format(f1))\n",
    "    print(count)\n",
    "    print(count_all)\n",
    "\n",
    "    count_all.append(count)\n",
    "    f1_all.append(f1)\n",
    "    print(f1_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Model </span> Use pre-trained word vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained the embedding vector for all words from these sentences with the MIMIC3 corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all TP, FP, TN, FN:  [[1, 0, 34, 5], [5, 0, 24, 11], [4, 0, 30, 6], [4, 1, 35, 0], [2, 0, 33, 5], [3, 1, 33, 3]]\n",
      "all f1:  [0.2857142857142857, 0.47619047619047616, 0.5714285714285715, 0.888888888888889, 0.4444444444444445, 0.6]\n",
      "macro f1:  0.6001340482573727\n",
      "micro f1:  0.5428571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"all TP, FP, TN, FN: \" ,count_all)\n",
    "print(\"all f1: \", f1_all)\n",
    "print(\"macro f1: \", count_f1(count_all)[0])\n",
    "print(\"micro f1: \", count_f1(count_all)[1])\n",
    "\n",
    "#count_f1(count_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
