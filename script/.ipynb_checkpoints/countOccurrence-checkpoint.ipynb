{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,os\n",
    "import random\n",
    "import string\n",
    "import logging\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "#import nltk\n",
    "import pickle\n",
    "from numpy import linalg as LA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filepath,i):\n",
    "    name = []\n",
    "    with open(filepath, \"rb\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            name.append(row[i])\n",
    "    return name\n",
    "def getsubset(name,text,pattern,site,algo):\n",
    "    #######get subset index\n",
    "    index = []\n",
    "    text_sub = []\n",
    "    site_sub = []\n",
    "    pattern_sub = []\n",
    "    algo_sub = []\n",
    "    for i in range(len(pattern)):\n",
    "        if pattern[i] in name:\n",
    "            text_sub.append(text[i])\n",
    "            pattern_sub.append(pattern[i])\n",
    "            site_sub.append(site[i])\n",
    "            algo_sub.append(algo[i])\n",
    "        else:\n",
    "            #print(pattern[i])\n",
    "            continue\n",
    "    return text_sub,pattern_sub, site_sub, algo_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all sentence: 190\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "pattern = []\n",
    "site = []\n",
    "algo = []\n",
    "with open(\"../data/sentence_all_info_0817.csv\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            text.append(row[0].strip())\n",
    "            pattern.append(row[1])\n",
    "            site.append(row[2])\n",
    "            algo.append(row[3])\n",
    "            \n",
    "print(\"number of all sentence:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique sentence: 154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match = {}\n",
    "for i in range(len(text)):\n",
    "    if text[i] in match:\n",
    "        match[text[i]].append(pattern[i])\n",
    "      \n",
    "    else:\n",
    "        match[text[i]] = [pattern[i]]\n",
    "\n",
    "print(\"number of unique sentence:\", len(match.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique sentence after subsetting: 131\n",
      "number of unique words after subsetting: 653\n"
     ]
    }
   ],
   "source": [
    "#name = [\"Medication Details\",\"Confirm Disease Was Checked\",\"Rule of N\",\"Use Distinct Dates\",\"Level of Evidence\",\"Credentials of the Actor\",\"Where Did It Happen?\",\"Check For Negation\"]#\n",
    "name = [\"Confirm Disease Was Checked\",\"Rule of N\",\"Use Distinct Dates\",\"Credentials of the Actor\",\"Where Did It Happen?\",\"Check For Negation\"]#\n",
    "#name = [\"Rule of N\",\"Use Distinct Dates\"]\n",
    "text_sub,pattern_sub,site_sub,algo_sub = getsubset(name,text,pattern,site,algo)\n",
    "unique_text_sub = list(set(text_sub))\n",
    "\n",
    "\n",
    "match_sub = {}\n",
    "for i in range(len(text_sub)):\n",
    "    if text_sub[i] in match_sub:\n",
    "        match_sub[text_sub[i]].append(pattern_sub[i])\n",
    "      \n",
    "    else:\n",
    "        match_sub[text_sub[i]] = [pattern_sub[i]]\n",
    "\n",
    "    \n",
    "unique_pattern = []\n",
    "for i in match_sub.values():\n",
    "    unique_pattern.append(i[0])\n",
    "\n",
    "print(\"number of unique sentence after subsetting:\", len(match_sub.keys()))  \n",
    "\n",
    "sum_words = {}\n",
    "for i in match_sub.keys():\n",
    "    for j in i.split(\" \"):\n",
    "        if j in sum_words:\n",
    "            continue\n",
    "        else:\n",
    "            sum_words[j] = 0\n",
    "print(\"number of unique words after subsetting:\", len(sum_words.keys()))\n",
    "\n",
    "all_site = []\n",
    "for sen in text_sub:\n",
    "    all_site.append(site_sub[text_sub.index(sen)])\n",
    "\n",
    "all_algo = []\n",
    "for sen in text_sub:\n",
    "    all_algo.append(algo_sub[text_sub.index(sen)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "\n",
    "#reload(sys)  \n",
    "#sys.setdefaultencoding('utf8')\n",
    "fn = '.../data/embedding_mimic3_pp200_0829.pik'\n",
    "f = open(fn, 'rb')\n",
    "a = pickle.load(f, encoding='bytes')\n",
    "(mem, hwoov, hwid) = a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encounter', 'with']\n"
     ]
    }
   ],
   "source": [
    "texts = \" \".join(text_sub)\n",
    "texts_words = texts.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = open(\"../data/word_occurance.txt\",\"w\")\n",
    "\n",
    "for i in list(hwid.keys()):\n",
    "    out.write(\" \".join([i.decode(\"utf-8\"),str(texts_words.count(i.decode(\"utf-8\")))])+\"\\n\")\n",
    "\n",
    "out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
