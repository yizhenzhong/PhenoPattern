{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence classification with support vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to perform the sentence classification with support vector machine algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport sklearn \\nfrom nltk.stem.porter import *\\n\\nfrom nltk.corpus import stopwords\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics.cluster import adjusted_mutual_info_score\\nfrom sklearn import preprocessing\\nfrom sklearn.cross_validation import train_test_split\\nfrom sklearn import preprocessing\\nfrom sklearn.metrics import roc_curve, auc,f1_score,adjusted_rand_score\\nfrom sklearn.cross_validation import StratifiedKFold\\nfrom pprint import pprint\\nfrom sklearn.grid_search import GridSearchCV\\nfrom optparse import OptionParser\\nfrom sklearn.cross_validation import StratifiedShuffleSplit\\nimport matplotlib.pyplot as plt\\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer,HashingVectorizer\\nfrom sklearn.svm import LinearSVC,SVC\\nfrom sklearn.utils.extmath import density\\nfrom sklearn.decomposition import TruncatedSVD\\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, adjusted_mutual_info_score, roc_auc_score, mutual_info_score, make_scorer, roc_curve,accuracy_score\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv,os\n",
    "import random\n",
    "import string\n",
    "import logging\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "#import nltk\n",
    "import pickle\n",
    "from numpy import linalg as LA\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "import sklearn \n",
    "from nltk.stem.porter import *\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc,f1_score,adjusted_rand_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from pprint import pprint\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from optparse import OptionParser\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, adjusted_mutual_info_score, roc_auc_score, mutual_info_score, make_scorer, roc_curve,accuracy_score\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filepath,i):\n",
    "    name = []\n",
    "    with open(filepath, \"rb\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            name.append(row[i])\n",
    "    return name\n",
    "\n",
    "#find the row which is 1\n",
    "def attach(feature,list):\n",
    "    index = [i for i, j in enumerate(list) if j == '1']\n",
    "    text = [feature[i] for i in index] \n",
    "    return text\n",
    "\n",
    "def match_feature(whole_text,traintext,testtext,feature):\n",
    "\ttrain = []\n",
    "\ttest = []\n",
    "\t#print traintext\n",
    "\tfor i in traintext:\n",
    "\t\ttrain.append(feature[whole_text.index(i)])\n",
    "\tfor i in testtext:\n",
    "\t\ttest.append(feature[whole_text.index(i)])\n",
    "\treturn train,test\n",
    "\n",
    "def makeSiteMatrix(wholesite,site_category):\n",
    "    site_matrix = []\n",
    "    for site in wholesite:\n",
    "        row = []\n",
    "        for c in site_category:\n",
    "            if c == site:\n",
    "                row.append(1)\n",
    "            else:\n",
    "                row.append(0)\n",
    "        site_matrix.append(row)\n",
    "    return site_matrix\n",
    "\n",
    "def removeNonAscii(s): \n",
    "    \"\"\"\n",
    "    s should be a utf-8 encoded string\n",
    "    \"\"\"\n",
    "    return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "def token(i):\n",
    "    a =  nltk.word_tokenize(i)\n",
    "    words = []\n",
    "    for j in a:\n",
    "        words.append(stemmer.stem(j))\n",
    "    return words \n",
    "\n",
    "def token_unstem(i):\n",
    "    a =  nltk.word_tokenize(i)\n",
    "    return a\n",
    "\n",
    "\n",
    "def words( TEXT ):\n",
    "    train = [] \n",
    "    #print TEXT  \n",
    "    for si in TEXT:\n",
    "        i = removeNonAscii(si)\n",
    "        i = i.lower()\n",
    "        #words = re.sub(\"[/*'-]\", \" \",i)\n",
    "        words = re.sub(\"[/'-]\", \" \",i) #replace with space\n",
    "        words = words.replace(\"[\", \" \")\n",
    "        words = words.replace(\"]\", \" \")\n",
    "        words = words.replace(\"(\", \" \")\n",
    "        words = words.replace(\")\", \" \")   \n",
    "        words = words.replace(\"=\", \" \")   \n",
    "        words = words.replace(\">\", \" \") \n",
    "        words = words.replace(\"*\", \" \")\n",
    "        words = words.replace(\"+\", \" \")\n",
    "        words = re.sub(r\"(^|\\s)[0-9]+[.][0-9x*_.]+($|\\s)\", \" _number_ \", words) #replace icd9 codes with icd_code   \n",
    "        words = re.sub(r\"(^|\\s)[,.\\-_>=<+?*/&\\\"\\'()\\[\\]]*[0-9]+[,.\\-_>=<+?*/&\\\"\\'()\\[\\]]*($|\\s)\", \" _number_ \", words) #replace single number to _number_\n",
    "        words = re.sub(r\"(^|\\s)[0-9]+($|\\s)\", \" _number_ \", words)    #replace single number with number\n",
    "        words = re.sub(r\"\\b(one|two|three|four)\\b\",\"_number_\",words) #replace word number to _number_\n",
    "        train.append(words)\n",
    "    return train\n",
    "\n",
    "def binary(values,l,name):\n",
    "    for ss in range(len(values)):\n",
    "        if name in values[ss]:\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return l\n",
    "\n",
    "def addmatrix(tfs_train_array,matrix,features,addfeatures,tfs_test_array,testmatrix):\n",
    "    matrix = preprocessing.normalize(matrix, norm='l2')\n",
    "    testmatrix = preprocessing.normalize(testmatrix, norm='l2')\n",
    "    tfs_train = np.hstack((tfs_train_array,matrix)) \n",
    "    tfs_test = np.hstack((tfs_test_array, testmatrix))  \n",
    "    features = features + addfeatures \n",
    "    return tfs_train,tfs_test,features\n",
    "\n",
    "def bag_of_words(train_text,test_text):\n",
    "    tfs = countvectorizer.fit_transform(train_text)\n",
    "    tfs_test = countvectorizer.transform(test_text)\n",
    "    features_words = countvectorizer.get_feature_names()\n",
    "    print(len(features_words))\n",
    "    tfs = preprocessing.normalize(tfs, norm='l2') \n",
    "    tfs_test = preprocessing.normalize(tfs_test, norm='l2') \n",
    "    tfs = tfs.toarray()\n",
    "    tfs_test = tfs_test.toarray()\n",
    "    return tfs, tfs_test,features_words\n",
    "\n",
    "def parse(file):\n",
    "    codelist = []\n",
    "    allcode = []\n",
    "    textlist = []\n",
    "    match = {}\n",
    "    temp = []\n",
    "    temp_stype=[]\n",
    "    temp_exp = {}\n",
    "    stype = []\n",
    "    stype_list = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            if line[0:24] == \"Processing 00000000.tx.1\":\n",
    "                temp = list(set(temp))\n",
    "                if temp != []:\n",
    "                    codelist = codelist + temp                   \n",
    "                temp = []\n",
    "                temp_stype = list(set(temp_stype))\n",
    "                # print temp_stype\n",
    "                if temp_stype != []:\n",
    "                    stype_list = stype_list + temp_stype\n",
    "                temp_stype = []\n",
    "\n",
    "                if codelist != []:\n",
    "                    allcode.append(codelist)\n",
    "                    #all_exp.append(exp_list)\n",
    "                if stype_list != []:\n",
    "                    stype.append(stype_list)\n",
    "                # print stype_list\n",
    "                text = line[26:]\n",
    "                textlist.append(text.rstrip())\n",
    "                codelist = []\n",
    "                stype_list = []\n",
    "                # print \"-----------------------------\"\n",
    "            elif line[0:6] == \"Phrase\":\n",
    "                temp = list(set(temp))\n",
    "                #temp_exp = list(set(temp_exp))\n",
    "                if temp != []:\n",
    "                    codelist = codelist + temp\n",
    "                    #z = temp_exp.copy()\n",
    "                    #z.update(codelist)\n",
    "                temp = []\n",
    "\n",
    "                temp_stype = list(set(temp_stype))\n",
    "                # print temp_stype\n",
    "                if temp_stype != []:\n",
    "                    stype_list = stype_list + temp_stype\n",
    "                temp_stype = []\n",
    "            else:\n",
    "                my = re.compile(\"C[0-9]{7}\")\n",
    "                # print line\n",
    "                result = my.findall(line)\n",
    "                if result != []:\n",
    "                    temp.append(result[0])\n",
    "                    a = line.index(\":\")\n",
    "                    temp_exp[result[0]] = str(line[a+1:-1])\n",
    "\n",
    "                my2 = re.compile(\"\\[.+\\]\")\n",
    "                result = my2.findall(line)\n",
    "                # print line\n",
    "                if result != []:\n",
    "                    temp_stype.append(result[0][1:-1])\n",
    "                    # print result[0]\n",
    "\n",
    "        codelist = codelist + list(set(temp))\n",
    "        # print temp_stype\n",
    "        stype_list = stype_list + list(set(temp_stype))\n",
    "        allcode.append(codelist)\n",
    "        stype.append(stype_list)\n",
    "    return allcode, textlist, temp_exp, stype\n",
    "\n",
    "#union of all codes\n",
    "def getunion(umls):\n",
    "    l = []\n",
    "    for i in umls:\n",
    "        l = list(set(l+i))\n",
    "    return l\n",
    "\n",
    "def umlsfeature(allcode,allwords):\n",
    "    whole = []\n",
    "    for i in allcode:\n",
    "        freq = []\n",
    "        for j in allwords:\n",
    "            if j in i:\n",
    "                freq.append(i.count(j))\n",
    "            else:\n",
    "                freq.append(0)\n",
    "        whole.append(freq)\n",
    "    whole = np.array(whole)\n",
    "    return whole\n",
    "\n",
    "def findOccurance(text, string):\n",
    "    occ = []\n",
    "    for i in text:\n",
    "        a = len([m.start() for m in re.finditer(string, i)])\n",
    "        occ.append(a)\n",
    "    return occ\n",
    "\n",
    "def reshape(x):\n",
    "    x1, x_cate = np.unique(x,return_inverse = True)\n",
    "    x_cate = x_cate.reshape(len(x),1)\n",
    "    return x_cate\n",
    "\n",
    "\n",
    "def embedding(tfs,tfs_test,numberOcc_train,numberOcc_test,mem):\n",
    "    tfs_train = np.dot(tfs, mem)#get train matrix \n",
    "    numberOcc_train = reshape(numberOcc_train)\n",
    "    tfs_train = np.hstack((tfs_train,numberOcc_train)) \n",
    "\n",
    "    tfs_test = np.dot(tfs_test, mem)\n",
    "    numberOcc_test = reshape(numberOcc_test)\n",
    "    tfs_test = np.hstack((tfs_test, numberOcc_test))\n",
    "    tfs_train = preprocessing.normalize(tfs_train, norm='l2')\n",
    "    tfs_test = preprocessing.normalize(tfs_test, norm='l2')\n",
    "    #get combined feature\n",
    "    features = list(range(200)) + [\"number\"]  \n",
    "    return tfs_train,tfs_test,features\n",
    "\n",
    "def print_feature(i):\n",
    "    print(name[i])\n",
    "    print(\"*\"*20)\n",
    "    a = [x for x,y in enumerate(patternlist_train[i]) if y == 1]\n",
    "    for aa in a:\n",
    "        print(all_train_text[aa])\n",
    "        print(\"baseline\")\n",
    "        print(x_train[aa].tolist())\n",
    "        print(\"baseline+site\")\n",
    "        print(x_train_site[aa].tolist())\n",
    "        print(\"baseline+algo\")\n",
    "        print(x_train_algo[aa].tolist())\n",
    "        print(\"baseline+CUI\")\n",
    "        print(x_train_CUI[aa].tolist())\n",
    "        print(\"baseline+st\")\n",
    "        print(x_train_st[aa].tolist())\n",
    "\"\"\"\n",
    "        print \"embedding\"\n",
    "        print x_train_embedding[aa]\n",
    "        print \"embedding+site\"\n",
    "        print x_train_em_site[aa]\n",
    "        print \"embedding+algo\"\n",
    "        print x_train_em_algo[aa]\n",
    "        print \"embedding+CUI\"\n",
    "        print x_train_em_cui[aa]\n",
    "        print \"embedding+st\"\n",
    "        print x_train_em_st[aa]\n",
    "\"\"\"\n",
    "def subset(worddict,features,mem):\n",
    "    subset_embedding = []\n",
    "    for ss in features:\n",
    "        if ss in worddict:\n",
    "            subset_embedding.append(mem[worddict[ss]])\n",
    "        else:\n",
    "            print(\"word not embedded\",ss)\n",
    "            subset_embedding.append([0] * len(mem[1]))\n",
    "    subset_embedding = np.asarray(subset_embedding)\n",
    "    return subset_embedding\n",
    "\n",
    "def count_f1(count_site):\n",
    "    #TP,FP,TN,FN\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    pre = []\n",
    "    recal = []\n",
    "    for lis in count_site:\n",
    "        TP = TP + lis[0]\n",
    "        FP = FP + lis[1]\n",
    "        FN = FN + lis[3]\n",
    "        if lis[0] + lis[1] == 0:\n",
    "            pre.append(0)\n",
    "        else:\n",
    "            pre.append(lis[0]/float((lis[0]+lis[1])))\n",
    "        recal.append(lis[0]/float((lis[0]+lis[3])))\n",
    "  \n",
    "    if TP + FP == 0:\n",
    "        micro_pres = 0\n",
    "    else:\n",
    "        micro_pres = float(TP)/(TP + FP)\n",
    "    #print micro_pres\n",
    "    micro_recall = float(TP)/(TP + FN)\n",
    "    #print micro_recall\n",
    "    f1 = 2*micro_pres*micro_recall/(micro_pres + micro_recall)\n",
    "    macro_pre = sum(pre)/len(count_site) \n",
    "    macro_recall = sum(recal)/len(count_site)\n",
    "    macro_f1 = 2*macro_pre*macro_recall/(macro_pre + macro_recall)\n",
    "    return macro_f1,f1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def makeBinaryMatrix(train_umls):\n",
    "    binary_matrix = []\n",
    "    for i in range(len(train_umls)):\n",
    "        row = []\n",
    "        for j in range(len(train_umls[i])):\n",
    "            if train_umls[i][j] != 0:\n",
    "                row.append(1)\n",
    "            else:\n",
    "                row.append(0)\n",
    "        binary_matrix.append(row)\n",
    "    return binary_matrix\n",
    "    \n",
    "def readtensor(filename):\n",
    "    F = open(filename,\"r\")\n",
    "    rank = []\n",
    "    for line in F:\n",
    "        line = line.rstrip()\n",
    "        ss = line.split(\" \")\n",
    "        ss = [float(i) for i in ss]\n",
    "        rank.append(ss)\n",
    "        #rank_10 = np.asarray(rank_10)\n",
    "    return rank\n",
    "\n",
    "def printfeature(feature_matrix, feature):\n",
    "    l = feature_matrix.tolist()\n",
    "    index = [i for i, j in enumerate(l) if j != 0]\n",
    "    for j in index:\n",
    "        print(l[j], feature[j])\n",
    "    #text = [feature[i] for i in index] \n",
    "    #print text\n",
    "    return text\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    COUNT = []\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==0 and y_hat[i] == 1:\n",
    "           FP += 1\n",
    "    \n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "    \n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==1 and y_hat[i] == 0:\n",
    "           FN += 1\n",
    "    return [TP,FP,TN,FN]\n",
    "\n",
    "def writecnninput(label,pos_out,neg_out,pos,neg):\n",
    "    for i in pos[label]:\n",
    "        pos_out.writelines(i+os.linesep)\n",
    "    for i in neg[label]:\n",
    "        neg_out.writelines(i+os.linesep)\n",
    "\n",
    "def getsubset(name,text,pattern,site,algo):\n",
    "    #######get subset index\n",
    "    index = []\n",
    "    text_sub = []\n",
    "    site_sub = []\n",
    "    pattern_sub = []\n",
    "    algo_sub = []\n",
    "    for i in range(len(pattern)):\n",
    "        if pattern[i] in name:\n",
    "            text_sub.append(text[i])\n",
    "            pattern_sub.append(pattern[i])\n",
    "            site_sub.append(site[i])\n",
    "            algo_sub.append(algo[i])\n",
    "        else:\n",
    "            #print(pattern[i])\n",
    "            continue\n",
    "    return text_sub,pattern_sub, site_sub, algo_sub\n",
    "\n",
    "\n",
    "\n",
    "def prediction(x_train,x_test,y_train,y_test,features):   \n",
    "    #tunning prarmeter\n",
    "    cv = StratifiedKFold(y_train, 3, random_state=0)\n",
    "    gs_clf = GridSearchCV(clf_linearsvc, parameter_linearsvc, n_jobs=-1,scoring =\"roc_auc\", cv = cv)\n",
    "    gs_clf = gs_clf.fit(x_train, y_train)\n",
    "    #print (\"best roc_auc score for cross_validation:\"),gs_clf.best_score_ \n",
    "    \n",
    "    #print(\"Best parameters set found on development set:\")\n",
    "    best_estimator = gs_clf.best_estimator_\n",
    "    #print(best_estimator)       \n",
    "    clf = best_estimator.fit(x_train,y_train)\n",
    "    coeff = clf.coef_\n",
    "    word = {}\n",
    "    for k in range(len(coeff[0])):\n",
    "        if coeff[0][k] != 0:\n",
    "            word[features[k]] = coeff[0][k]\n",
    "    print(\"\\n\")\n",
    "    print(\"rank feature in decreasing order:\")\n",
    "    print(sorted(word.items(), key=lambda x: x[1], reverse=True)[0:20])\n",
    "    probas_ = clf.decision_function(x_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_)\n",
    "    roc_auc = auc(fpr, tpr) \n",
    "    #print(\"roc_auc of prediction: %f\" %roc_auc)    \n",
    "    pred = clf.predict(x_test)\n",
    "    preds = clf.predict(x_train)\n",
    "    f1 = f1_score(y_test, pred, average='binary')\n",
    "    print(\"f1 score\", f1)\n",
    "    print(\"predicted label\",pred)\n",
    "    print(\"true label\",y_test)\n",
    "    #print x_train[1]\n",
    "    #print x_train.shape\n",
    "    #printfeature(x_train[0],features)\n",
    "    #for ss in range(len(preds)):\n",
    "    #    if preds[ss] != y_train[ss]:\n",
    "    #        print y_train[ss]\n",
    "    #        print all_train_text[ss]\n",
    "    #        printfeature(x_train[ss],features)\n",
    "    a = perf_measure(y_test, pred)\n",
    "    #print(classification_report(y_test, pred))\n",
    "    print('_' * 50)\n",
    "    return a,f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and collect features (develop sites and algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all sentence: 190\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "pattern = []\n",
    "site = []\n",
    "algo = []\n",
    "with open(\"../data/sentence_all_info_0817.csv\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if len(row) == 0:\n",
    "                continue\n",
    "            text.append(row[0].strip())\n",
    "            pattern.append(row[1])\n",
    "            site.append(row[2])\n",
    "            algo.append(row[3])\n",
    "            \n",
    "print(\"number of all sentence:\", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentences to a dict, in which the key is the sentence and value is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique sentence: 154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match = {}\n",
    "for i in range(len(text)):\n",
    "    if text[i] in match:\n",
    "        match[text[i]].append(pattern[i])\n",
    "      \n",
    "    else:\n",
    "        match[text[i]] = [pattern[i]]\n",
    "\n",
    "print(\"number of unique sentence:\", len(match.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use 6 classes with large number of sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique sentence after subsetting: 131\n",
      "number of unique words after subsetting: 653\n"
     ]
    }
   ],
   "source": [
    "#name = [\"Medication Details\",\"Confirm Disease Was Checked\",\"Rule of N\",\"Use Distinct Dates\",\"Level of Evidence\",\"Credentials of the Actor\",\"Where Did It Happen?\",\"Check For Negation\"]#\n",
    "name = [\"Confirm Disease Was Checked\",\"Rule of N\",\"Use Distinct Dates\",\"Credentials of the Actor\",\"Where Did It Happen?\",\"Check For Negation\"]#\n",
    "#name = [\"Rule of N\",\"Use Distinct Dates\"]\n",
    "text_sub,pattern_sub,site_sub,algo_sub = getsubset(name,text,pattern,site,algo)\n",
    "unique_text_sub = list(set(text_sub))\n",
    "\n",
    "\n",
    "match_sub = {}\n",
    "for i in range(len(text_sub)):\n",
    "    if text_sub[i] in match_sub:\n",
    "        match_sub[text_sub[i]].append(pattern_sub[i])\n",
    "      \n",
    "    else:\n",
    "        match_sub[text_sub[i]] = [pattern_sub[i]]\n",
    "\n",
    "    \n",
    "unique_pattern = []\n",
    "for i in match_sub.values():\n",
    "    unique_pattern.append(i[0])\n",
    "\n",
    "print(\"number of unique sentence after subsetting:\", len(match_sub.keys()))  \n",
    "\n",
    "sum_words = {}\n",
    "for i in match_sub.keys():\n",
    "    for j in i.split(\" \"):\n",
    "        if j in sum_words:\n",
    "            continue\n",
    "        else:\n",
    "            sum_words[j] = 0\n",
    "print(\"number of unique words after subsetting:\", len(sum_words.keys()))\n",
    "\n",
    "all_site = []\n",
    "for sen in text_sub:\n",
    "    all_site.append(site_sub[text_sub.index(sen)])\n",
    "\n",
    "all_algo = []\n",
    "for sen in text_sub:\n",
    "    all_algo.append(algo_sub[text_sub.index(sen)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = 100\n",
    "sss = StratifiedShuffleSplit(unique_pattern, 1, test_size=0.3, random_state=seed)\n",
    "for train_index, test_index in sss:\n",
    "    X_train, X_test = [list(match_sub.keys())[i] for i in train_index], [list(match_sub.keys())[i] for i in test_index]\n",
    "    y_train, y_test = [list(match_sub.values())[i] for i in train_index], [list(match_sub.values())[i] for i in test_index]\n",
    "    site_train, site_test = [all_site[i] for i in train_index], [all_site[i] for i in test_index]\n",
    "    algo_train, algo_test = [all_algo[i] for i in train_index], [all_algo[i] for i in test_index]\n",
    "\n",
    "X_train_process = words(X_train)\n",
    "X_test_process = words(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "patternlist_train = []\n",
    "patternlist_test = []\n",
    "for i in range(len(name)):\n",
    "    l = []\n",
    "    s = []\n",
    "    a = binary(y_train,l,name[i])\n",
    "    b = binary(y_test,s,name[i])\n",
    "    patternlist_train.append(a)\n",
    "    patternlist_test.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write positive and negative sentences for the CNN classification usage\n",
    "\n",
    "def write_sentence(i):\n",
    "    label_class = name[i]\n",
    "    print(\"processing: \", label_class)\n",
    "    label = \"_\".join(label_class.split())\n",
    "\n",
    "    print(\"positive sentences: \", sum([x==1 for x in patternlist_train[i]]))\n",
    "    trainpos = \"../data/cnn/\"+label+\"_seed\"+str(seed)+\"replace_0403_train.txt\"\n",
    "    trainneg = trainpos.replace(\"train\", \"train_rest\")\n",
    "    testpos = trainpos.replace(\"train\", \"test\")\n",
    "    testneg = trainneg.replace(\"train\", \"test\")\n",
    "    trainpos_w = open(trainpos,\"w\")\n",
    "    trainneg_w = open(trainneg,\"w\")\n",
    "    testpos_w = open(testpos,\"w\")\n",
    "    testneg_w = open(testneg,\"w\")\n",
    "\n",
    "    \n",
    "    for sen in range(len(X_train_process)):\n",
    "        if patternlist_train[i][sen] == 1:  \n",
    "            trainpos_w.writelines(X_train_process[sen]+os.linesep)\n",
    "        else:\n",
    "            trainneg_w.writelines(X_train_process[sen]+os.linesep)\n",
    "\n",
    "    for sen in range(len(X_test_process)):\n",
    "        if patternlist_test[i][sen] == 1:\n",
    "            testpos_w.writelines(X_test_process[sen]+os.linesep)\n",
    "        else:\n",
    "            testneg_w.writelines(X_test_process[sen]+os.linesep)\n",
    "\n",
    "\n",
    "    trainpos_w.close()\n",
    "    trainneg_w.close()\n",
    "    testpos_w.close() \n",
    "    testneg_w.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing:  Confirm Disease Was Checked\n",
      "positive sentences:  15\n",
      "processing:  Rule of N\n",
      "positive sentences:  33\n",
      "processing:  Use Distinct Dates\n",
      "positive sentences:  26\n",
      "processing:  Credentials of the Actor\n",
      "positive sentences:  13\n",
      "processing:  Where Did It Happen?\n",
      "positive sentences:  12\n",
      "processing:  Check For Negation\n",
      "positive sentences:  15\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    write_sentence(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process site and algorithm features\n",
    "site_category = list(set(all_site))\n",
    "algo_category = list(set(all_algo))\n",
    "\n",
    "all_train_site = makeSiteMatrix(site_train,site_category)\n",
    "all_test_site = makeSiteMatrix(site_test,site_category)\n",
    "all_train_algo = makeSiteMatrix(algo_train,algo_category)\n",
    "all_test_algo = makeSiteMatrix(algo_test,algo_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process CUI and ST features\n",
    "#read umls file\n",
    "allcode_train, textlist_train,all_exp,all_st_train = parse(\"../data/umls_train_0623.txt\")\n",
    "allcode_test,textlist_test,test_exp,all_st_test = parse(\"../data/umls_test_0624.txt\")\n",
    "\n",
    "all_text_umls = textlist_train + textlist_test\n",
    "all_cui_umls = allcode_train + allcode_test\n",
    "#all_exp_umls = all_exp + test_exp\n",
    "all_st_umls = all_st_train + all_st_test\n",
    "\n",
    "allcode_train = list(map(lambda x: all_cui_umls[all_text_umls.index(x)], X_train))\n",
    "allcode_test = list(map(lambda x: all_cui_umls[all_text_umls.index(x)], X_test))\n",
    "all_st_train = list(map(lambda x: all_st_umls[all_text_umls.index(x)], X_train))\n",
    "all_st_test = list(map(lambda x: all_st_umls[all_text_umls.index(x)], X_test))\n",
    "\n",
    "#get the union of all CUI code and st\n",
    "CUI = getunion(allcode_train)\n",
    "st = getunion(all_st_train)\n",
    "\n",
    "all_train_CUI = umlsfeature(allcode_train,CUI)\n",
    "all_test_CUI = umlsfeature(allcode_test,CUI)\n",
    "all_train_st = umlsfeature(all_st_train,st)\n",
    "all_test_st = umlsfeature(all_st_test,st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/embedding/embedding_mimic3_pp200_0829.pik'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d58003783e55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#sys.setdefaultencoding('utf8')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/embedding/embedding_mimic3_pp200_0829.pik'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhwoov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhwid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/embedding/embedding_mimic3_pp200_0829.pik'"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "\n",
    "#reload(sys)  \n",
    "#sys.setdefaultencoding('utf8')\n",
    "fn = '../data/embedding/embedding_mimic3_pp200_0829.pik'\n",
    "f = open(fn, 'rb')\n",
    "a = pickle.load(f, encoding='bytes')\n",
    "(mem, hwoov, hwid) = a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "stop = []\n",
    "f = open(\"stoplist3.txt\")\n",
    "stop = f.read().splitlines() #stop list containing have\n",
    "clf_linearsvc = LinearSVC(dual=False, class_weight=\"balanced\",random_state = 0)\n",
    "C_range = list(10**x for x in range(-6,3))\n",
    "parameter_linearsvc = {\"C\" : C_range,\n",
    "                        \"penalty\":[\"l2\",\"l1\"]}\n",
    "countvectorizer = TfidfVectorizer(tokenizer=token_unstem, stop_words=stop,decode_error =\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367\n"
     ]
    }
   ],
   "source": [
    "#get the pattern list for each class\n",
    "x_train_fit, x_test_fit,features = bag_of_words(X_train_process,X_test_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('measurements', 1.0018888881540238), ('eye', 0.9832323199287365), ('results', 0.94170763798561929), ('note', 0.93165378115749709), ('negative', 0.84214252323647398), ('day', 0.81818514923779251), ('normal', 0.81267697147746942), ('ecg', 0.80583910657297309), ('performed', 0.70351624259310053), ('check', 0.70351624259310053), ('lab', 0.65806181405494524), ('individuals', 0.62628690906314077), ('exam', 0.59840533708327492), ('absent', 0.56624718593912837), ('controls', 0.56624718593912837), ('have', 0.56575193866066353), ('past', 0.55647437768604613), ('colitis', 0.4964880429927267), ('ulcerative', 0.4964880429927267), ('screen', 0.4964880429927267)]\n",
      "f1 score 0.444444444444\n",
      "predicted label [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[2, 1, 33, 4]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('_number_', 1.196658834727254e-05), ('more', 9.4681818026682803e-06), ('visits', 6.802861359094117e-06), ('person', 5.6312748433253607e-06), ('days', 5.3748266474765403e-06), ('separate', 5.1616178402666385e-06), ('relevant', 4.6231999983294588e-06), ('icd9', 4.1771749094157203e-06), ('calendar', 3.9750726136330791e-06), ('diagnoses', 3.8221910541291644e-06), ('above', 3.5171711100008508e-06), ('see', 3.3637044100692845e-06), ('having', 3.2894581404375148e-06), ('medication', 3.2112189692857427e-06), ('gerd', 3.0558096442816184e-06), ('code', 2.9008301941439434e-06), ('occasions', 2.8672304583616873e-06), ('classes', 2.7012364725890007e-06), ('different', 2.3130806339451205e-06), ('atopic', 2.0924118115424994e-06)]\n",
      "f1 score 0.833333333333\n",
      "predicted label [0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[15, 5, 19, 1]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('occasions', 1.596851507654756), ('days', 1.5639326777673852), ('apart', 1.4602785726415537), ('chf', 1.293052053669848), ('distinct', 1.2339487903730468), ('months', 1.2008531188867668), ('dates', 1.0446840377784732), ('_number_', 1.0326230735449415), ('ml', 0.98265238559736845), ('separate', 0.94253084068944237), ('separated', 0.92069649822316968), ('dm', 0.8465295359492836), ('most', 0.80960804567741518), ('calendar', 0.76795778764064837), ('0.5', 0.76774469630891951), ('kg', 0.76774469630891951), ('abnormal', 0.7627904300189905), ('rx', 0.72590308214677313), ('supplies', 0.72590308214677313), ('tests', 0.70261930644552228)]\n",
      "f1 score 0.705882352941\n",
      "predicted label [0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[6, 1, 29, 4]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('ophthalmology', 1.4414089683506767e-05), ('optometry', 1.4414089683506767e-05), ('department', 1.0153830639338603e-05), ('select', 9.3824049728155928e-06), ('having', 9.3522087354671379e-06), ('within', 9.0504763299961539e-06), ('provider', 9.0274649286453351e-06), ('subjects', 8.8006813258797125e-06), ('above', 7.2227983748957991e-06), ('see', 7.1086806066559469e-06), ('diagnoses', 6.8621012395096757e-06), ('clinical', 6.7974568765071148e-06), ('from', 6.6901483448485455e-06), ('optometrist', 6.4500584261087235e-06), ('given', 6.4500584261087235e-06), ('ophthalmologist', 6.4500584261087235e-06), ('open', 6.3617717248418365e-06), ('glaucoma', 6.3617717248418365e-06), ('angle', 6.3617717248418365e-06), ('encounter', 5.6504293135528619e-06)]\n",
      "f1 score 0.5\n",
      "predicted label [0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 1]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 8, 28, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('inpatient', 1.1105972354066657e-05), ('admission', 9.5164969860477033e-06), ('hospital', 8.1497750609149261e-06), ('discharge', 6.7149339496426016e-06), ('hours', 6.2891900178358381e-06), ('hospitalization', 6.0989037623276273e-06), ('during', 5.7054996632538092e-06), ('mrsa', 5.4472327416269054e-06), ('outpatient', 5.2717888831927903e-06), ('date', 5.2534716138077942e-06), ('considering', 4.9826460002761424e-06), ('year', 4.763624867476252e-06), ('prior', 4.3024187487571546e-06), ('cpt', 3.6373720298748484e-06), ('excluded', 3.2719182717054385e-06), ('antibiotics', 3.2696749682780636e-06), ('after', 3.2252328209147965e-06), ('at', 3.2041468826359515e-06), ('stay', 3.1754006129931256e-06), ('keep', 3.1754006129931256e-06)]\n",
      "f1 score 0.521739130435\n",
      "predicted label [0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0\n",
      " 1 1 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[6, 10, 23, 1]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('terms', 1.3048131732674646), ('negative', 0.92164009891040199), ('mention', 0.88963517769085976), ('evidence', 0.85062282442378856), ('negated', 0.83177953975056274), ('appendicitis', 0.70370824787751318), ('reported', 0.70370824787751318), ('history', 0.66781284684730169), ('no', 0.66252459959046939), ('characters', 0.64603965540633335), ('dt', 0.6365049451810062), ('cnt', 0.6365049451810062), ('pt', 0.6365049451810062), ('t1dm', 0.6365049451810062), ('diff', 0.60423755456034167), ('concepts', 0.54669275410375517), ('impression', 0.54669275410375517), ('notes', 0.53650278957627096), ('diabetic', 0.52410474446106969), ('family', 0.51790613787435391)]\n",
      "f1 score 0.769230769231\n",
      "predicted label [0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[5, 2, 32, 1]\n",
      "[0.44444444444444442, 0.83333333333333337, 0.70588235294117641, 0.5, 0.52173913043478248, 0.76923076923076916]\n",
      "macro_f1:  0.6805961734509994\n",
      "micro_f1:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_fit, x_test_fit,patternlist_train[i],patternlist_test[i],features)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('measurements', 1.353896222210208), ('note', 1.1818103933220776), ('eye', 1.0631239898959535), ('day', 1.0138794417665571), ('negative', 0.96957961851811914), ('results', 0.96271936754157283), ('normal', 0.90678660964441882), ('performed', 0.89085631330949944), ('check', 0.89085631330949944), ('ecg', 0.87573296585709326), ('lab', 0.74955725812378082), ('absent', 0.66448445098868891), ('controls', 0.66448445098868891), ('colitis', 0.65600437879957163), ('ulcerative', 0.65600437879957163), ('screen', 0.65600437879957163), ('production', 0.65301837517303485), ('proceed', 0.65301837517303485), ('shift', 0.65301837517303485), ('hour', 0.65301837517303485)]\n",
      "f1 score 0.0\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[0, 1, 33, 6]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('_number_', 3.5462180852669656), ('more', 2.1573179030922458), ('medication', 1.6644598547047555), ('diagnoses', 1.4579475838049361), ('chd', 1.2926543481890225), ('chf', 1.2706109873930442), ('bmi', 1.0774022053752217), ('see', 1.0118329516438209), ('classes', 0.83015668038802259), ('medical', 0.79990580856181637), ('visits', 0.69792489985676998), ('primary', 0.67956581822945616), ('glucose', 0.57442474832031454), ('having', 0.54084990011625045), ('first', 0.49001492954276271), ('remaining', 0.35211708630446276), ('ge', 0.32891721941902496), ('occasions', 0.24638618868980861), ('gerd', 0.21840023138573994), ('abnormal', 0.16366129656804587)]\n",
      "f1 score 0.733333333333\n",
      "predicted label [1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[11, 3, 21, 5]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('days', 4.2109292024955671), ('distinct', 2.921264912610384), ('months', 2.707238863638505), ('separated', 2.2366282654102232), ('apart', 2.1831789643619417), ('_number_', 1.894218018774382), ('chf', 1.8706304556881796), ('dates', 1.7617949213554014), ('kg', 1.3975815172091275), ('occasions', 1.1523125530111151), ('0.5', 0.69033156453242661), ('kidney', 0.56552652531923675), ('different', 0.41721152161764247), ('Northwestern', 0.31826883515309512), ('ml', 0.28143088022616608), ('most', 0.15302294016561582), ('Columbia', 0.060220217108032353), ('relevant', 0.042559646592643913), ('damage', 0.033089299949392019), ('CHOP', -0.01979015845256708)]\n",
      "f1 score 1.0\n",
      "predicted label [0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[10, 0, 30, 0]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('clinical', 1.2411859530490055), ('following', 0.96478947823899408), ('psychology', 0.94571904070146473), ('provider', 0.90647934251415252), ('ophthalmology', 0.88245605572585428), ('optometry', 0.88245605572585428), ('providers', 0.77696227061956191), ('diagnosis', 0.59456501376262438), ('department', 0.56295745578456813), ('above', 0.51473486634056587), ('within', 0.50713978033779517), ('derived', 0.49706499429137407), ('excludes', 0.49706499429137407), ('entered', 0.49706499429137407), ('sources', 0.49706499429137407), ('neurology', 0.47285952035073237), ('developmental', 0.47285952035073237), ('seen', 0.47285952035073237), ('departments', 0.47285952035073237), ('from', 0.4580789228716422)]\n",
      "f1 score 1.0\n",
      "predicted label [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 0, 36, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('inpatient', 6.1365801832434368), ('hospital', 4.8056479555217333), ('discharge', 4.5806689602459798), ('outpatient', 4.1306704129744327), ('meeting', 0.58768654658179864), ('Geisinger', 0.16507596892385595), ('CHOP', 0.13807019988249863), ('after', 0.12494789822973114), ('considering', 0.09778193762893031), ('Mayo', 0.017868021612280481), ('Mount Sinai', -0.03348245123108478)]\n",
      "f1 score 0.769230769231\n",
      "predicted label [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[5, 1, 32, 2]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('terms', 1.5911486436890701), ('evidence', 0.96482110506152563), ('negated', 0.93321019573537345), ('mention', 0.8713255189181387), ('exclusion', 0.8335362124214325), ('appendicitis', 0.79575824454716781), ('reported', 0.79575824454716781), ('negative', 0.79108605122657327), ('no', 0.73619874244918304), ('diabetic', 0.71907536201497579), ('dt', 0.71800128496701954), ('cnt', 0.71800128496701954), ('pt', 0.71800128496701954), ('t1dm', 0.71800128496701954), ('concepts', 0.64652359627628575), ('impression', 0.64652359627628575), ('characters', 0.64651332270118012), ('notes', 0.63888473308468363), ('diff', 0.6318665376020447), ('history', 0.62612464430756909)]\n",
      "f1 score 0.727272727273\n",
      "predicted label [0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[4, 1, 33, 2]\n",
      "[0.0, 0.73333333333333339, 1.0, 1.0, 0.76923076923076916, 0.72727272727272718]\n",
      "macro_f1:  0.7060848230635735\n",
      "micro_f1:  0.7640449438202247\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_site,x_test_site,features_site = addmatrix(x_train_fit,all_train_site,features,site_category,x_test_fit,all_test_site)\n",
    "\n",
    "\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_site, x_test_site,patternlist_train[i],patternlist_test[i],features_site)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('eye', 1.0189959098193691), ('measurements', 1.0139660029556319), ('results', 0.93219004093266011), ('Ocular Hypertension', 0.865824633497153), ('negative', 0.82274441878886806), ('performed', 0.80285853841186106), ('check', 0.80285853841186106), ('day', 0.77433406235718294), ('ecg', 0.76976396106450418), ('normal', 0.7642619097754545), ('Appendicitis', 0.74159973589686745), ('lab', 0.67679383809863591), ('note', 0.65888216336524852), ('exam', 0.64456423110595096), ('individuals', 0.57131600899580326), ('keywords', 0.55810887400384002), ('af', 0.55810887400384002), ('absent', 0.50569601681493881), ('controls', 0.50569601681493881), ('criteria', 0.49840676454268035)]\n",
      "f1 score 0.0\n",
      "predicted label [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[0, 2, 32, 6]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('more', 3.1739373392877983), ('_number_', 2.7561942243739863), ('medication', 2.0558763154939395), ('diagnoses', 2.0282124520523932), ('primary', 1.4521299867131487), ('different', 1.0474918309359502), ('chd', 1.0426670765396413), ('occasions', 0.91773819127644429), ('below', 0.86052608940997999), ('HDL', 0.84240639491890612), ('Herpes Zoster', 0.83247218159874736), ('chf', 0.80803199955022731), ('CHD', 0.72674507853604875), ('gerd', 0.57210169054241378), ('AKI', 0.50309714912438264), ('classes', 0.4989202270307157), ('first', 0.49010376577220832), ('Extreme Obesity', 0.35402968587896078), ('Hypothyroidism', 0.3242408427041964), ('having', 0.25258970812776227)]\n",
      "f1 score 0.758620689655\n",
      "predicted label [1 0 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[11, 2, 22, 5]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('distinct', 6.0775073156439765), ('months', 5.2797801169998584), ('most', 4.2480628046960085), ('mg', 4.0430563418527949), ('apart', 3.6646787707917605), ('separated', 3.5886805826007575), ('0.5', 2.6220466499272508), ('occasions', 2.5696156290412722), ('separate', 2.1410009653743214), ('C Diff', 1.9885226000077805), ('days', 1.943251577864344), ('kg', 1.4654685575365658), ('calendar', 1.2110891854359078), ('measurements', 1.1842174642906151), ('_number_', 1.1767900874490225), ('HDL', 1.1352956456013996), ('subject', 0.99069075097935322), ('ADHD', 0.81384720101174957), ('relevant', 0.67185249548762793), ('dermatitis', 0.46317319484189279)]\n",
      "f1 score 0.823529411765\n",
      "predicted label [0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[7, 0, 30, 3]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('GERD', 2.0999152812030906e-05), ('ophthalmology', 1.441394664449025e-05), ('optometry', 1.441394664449025e-05), ('department', 1.0153696456833977e-05), ('select', 9.3823313572339921e-06), ('having', 9.3521342327846738e-06), ('within', 9.0504010597344253e-06), ('provider', 9.0273857141418414e-06), ('subjects', 8.8006080907870194e-06), ('above', 7.2227705547869802e-06), ('see', 7.1086513720880182e-06), ('Afib', 6.9998992173199723e-06), ('Autism', 6.9997462459805736e-06), ('Cdiff', 6.9997328380293116e-06), ('diagnoses', 6.8620765541218366e-06), ('clinical', 6.7974275034421299e-06), ('from', 6.6900817289913033e-06), ('optometrist', 6.4499823428623318e-06), ('given', 6.4499823428623318e-06), ('ophthalmologist', 6.4499823428623318e-06)]\n",
      "f1 score 0.380952380952\n",
      "predicted label [0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 0 1\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 13, 23, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('outpatient', 4.5480590831649002), ('hospital', 4.152315730887759), ('inpatient', 3.8359805340586846), ('meeting', 2.973665531823622), ('hospitalization', 2.4026840962287999), ('discharge', 2.3540393428133295), ('during', 1.4989821571011024), ('admission', 1.263253803525771), ('AAA', 1.1863410640733432), ('PAD', 1.1649127727520621), ('Obesity', 0.98668379501145642), ('mrsa', 0.31520014634939841), ('considering', 0.13099151158519928), ('QRS Duration', 0.013279133259088222), ('AMD', -0.39264002522417329)]\n",
      "f1 score 0.8\n",
      "predicted label [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 0 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[6, 2, 31, 1]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('terms', 1.4479587318997913), ('mention', 0.92782004220978842), ('negative', 0.910823285689214), ('evidence', 0.88037953535842772), ('characters', 0.82047660307843218), ('exclusion', 0.7664952907142647), ('negated', 0.74040776270271236), ('QRS', 0.68343855896478212), ('diabetic', 0.66532904397151493), ('dt', 0.64185810300638979), ('cnt', 0.64185810300638979), ('pt', 0.64185810300638979), ('t1dm', 0.64185810300638979), ('diff', 0.64009421781825726), ('no', 0.61539270056712747), ('concepts', 0.57025430302272651), ('impression', 0.57025430302272651), ('family', 0.56414319312986672), ('without', 0.55664098390241323), ('Dementia', 0.55615329800114643)]\n",
      "f1 score 0.6\n",
      "predicted label [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[3, 1, 33, 3]\n",
      "[0.0, 0.75862068965517238, 0.82352941176470584, 0.38095238095238093, 0.79999999999999993, 0.59999999999999998]\n",
      "macro_f1:  0.610204626344332\n",
      "micro_f1:  0.62\n"
     ]
    }
   ],
   "source": [
    "x_train_algo,x_test_algo,features_algo = addmatrix(x_train_fit,all_train_algo,features,algo_category,x_test_fit,all_test_algo)\n",
    "\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_algo, x_test_algo,patternlist_train[i],patternlist_test[i],features_algo)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('measurements', 0.6074900536170692), ('eye', 0.60506203972917594), ('C0200149', 0.60276911520819443), ('results', 0.55841269289985218), ('note', 0.53975394249278241), ('day', 0.52079874250508829), ('negative', 0.47030924782712469), ('C0242485', 0.46826933262441417), ('exam', 0.45614126655323062), ('C0205447', 0.44356095097006576), ('C1316572', 0.43366176797579881), ('C1707391', 0.41438277067465534), ('C0022877', 0.39881196722090978), ('ecg', 0.39749114049997392), ('individuals', 0.39217285537283536), ('check', 0.38898867765912409), ('performed', 0.38898867765912409), ('have', 0.38145022903413101), ('lab', 0.35998877471220164), ('normal', 0.34937886547398539)]\n",
      "f1 score 0.285714285714\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[1, 0, 34, 5]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('_number_', 1.1966497132677875e-05), ('C0205172', 1.0993820973148595e-05), ('C0205448', 9.5235262232386679e-06), ('more', 9.4681096320261321e-06), ('visits', 6.8028095046955683e-06), ('person', 5.6312319192740463e-06), ('days', 5.3747856781860615e-06), ('separate', 5.161578496147375e-06), ('C0439228', 4.894783555710121e-06), ('relevant', 4.6231647582675746e-06), ('icd9', 4.1771430691530534e-06), ('calendar', 3.9750423138829172e-06), ('C0805701', 3.9467150893515388e-06), ('C3889831', 3.9467150893515388e-06), ('C0009219', 3.9467150893515388e-06), ('C0443299', 3.8354490030227468e-06), ('diagnoses', 3.8221619197094274e-06), ('C1512346', 3.8216243945228363e-06), ('C0545082', 3.8216243945228363e-06), ('C2346503', 3.69907378368534e-06)]\n",
      "f1 score 0.8\n",
      "predicted label [0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[16, 8, 16, 0]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('months', 6.2430439946911251), ('separated', 6.168596309427163), ('days', 3.837690529673278), ('subject', 3.2510169912000606), ('apart', 3.2393348800360751), ('most', 2.7416261643876356), ('dates', 2.7357867444848107), ('supplies', 2.4498174576882841), ('occasions', 2.4097378292791189), ('relevant', 1.896212858468465), ('distinct', 1.8392654676068576), ('ml', 1.6314979918770971), ('C0018802', 1.5683193812532923), ('chf', 1.5253125719415115), ('occur', 1.5062363731586199), ('0.5', 1.3557387367288427), ('kg', 1.3027138950146957), ('separate', 1.0917841261939825), ('C1551058', 1.0475458496474983), ('C0750480', 0.96500018015360289)]\n",
      "f1 score 0.823529411765\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[7, 0, 30, 3]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('optometry', 1.4413859182298072e-05), ('ophthalmology', 1.4413859182298072e-05), ('department', 1.0153636254079288e-05), ('select', 9.3822265540733218e-06), ('having', 9.3520312705892992e-06), ('within', 9.0503090732901712e-06), ('provider', 9.0273349352536958e-06), ('C1704729', 8.8398583823017071e-06), ('subjects', 8.8005051533699876e-06), ('C1138603', 8.1882560370697063e-06), ('C3871137', 7.2846598604112815e-06), ('above', 7.2227109829964713e-06), ('see', 7.1085930461942318e-06), ('diagnoses', 6.8620267020743206e-06), ('clinical', 6.7973753262649976e-06), ('C0011900', 6.7851880573293434e-06), ('from', 6.6900018554031216e-06), ('C0029147', 6.657684778849183e-06), ('C0587524', 6.657684778849183e-06), ('C0919279', 6.6248716965906883e-06)]\n",
      "f1 score 0.444444444444\n",
      "predicted label [0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 10, 26, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('C0021562', 1.2133320146752947e-05), ('inpatient', 1.1105806480584987e-05), ('C1548438', 9.8469073509908679e-06), ('C1549404', 9.8469073509908679e-06), ('admission', 9.5163483706768528e-06), ('hospital', 8.1496910442062205e-06), ('discharge', 6.7148701113509253e-06), ('C1548439', 6.4423797498976453e-06), ('C1549405', 6.4423797498976453e-06), ('C0029921', 6.4423797498976453e-06), ('hours', 6.2890812448993167e-06), ('hospitalization', 6.0988320036229962e-06), ('C0184666', 6.0624092272985532e-06), ('during', 5.7054405279266614e-06), ('mrsa', 5.447175455370558e-06), ('outpatient', 5.2717398483349825e-06), ('date', 5.2533835016493699e-06), ('considering', 4.9825823926453722e-06), ('year', 4.7635751740856151e-06), ('C1292423', 4.7619159194234385e-06)]\n",
      "f1 score 0.545454545455\n",
      "predicted label [0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0\n",
      " 1 1 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[6, 9, 24, 1]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('C1518422', 0.79377021046604368), ('negative', 0.74357592393945893), ('mention', 0.60331553329030252), ('terms', 0.5703391744119487), ('C1705313', 0.5493073186254418), ('negated', 0.47001638889635677), ('C0233324', 0.45998935656389384), ('C1515273', 0.45998935656389384), ('C2826302', 0.45998935656389384), ('evidence', 0.45705866591050442), ('appendicitis', 0.41373119871091407), ('reported', 0.41373119871091407), ('C0684224', 0.381323344915869), ('C0455547', 0.381323344915869), ('C0700287', 0.381323344915869), ('history', 0.37408708523542611), ('no', 0.371786325978815), ('t1dm', 0.35174552692482952), ('dt', 0.35174552692482952), ('cnt', 0.35174552692482952)]\n",
      "f1 score 0.727272727273\n",
      "predicted label [0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[4, 1, 33, 2]\n",
      "[0.2857142857142857, 0.80000000000000004, 0.82352941176470584, 0.44444444444444448, 0.54545454545454553, 0.72727272727272718]\n",
      "macro_f1:  0.7113517722213374\n",
      "micro_f1:  0.6608695652173914\n"
     ]
    }
   ],
   "source": [
    "x_train_CUI,x_test_CUI,features_CUI = addmatrix(x_train_fit,all_train_CUI,features,CUI,x_test_fit,all_test_CUI)\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_CUI, x_test_CUI,patternlist_train[i],patternlist_test[i],features_CUI)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('measurements', 0.9977168352719471), ('note', 0.9731372796982154), ('results', 0.95439131844768943), ('eye', 0.92363200356560315), ('day', 0.91193380619588849), ('negative', 0.79610325191892861), ('ecg', 0.73151896909210323), ('exam', 0.71165613125263483), ('Therapeutic or Preventive Procedure', 0.70576406119873158), ('Human', 0.67620313104547358), ('must', 0.64691459116799765), ('normal', 0.63019841795629572), ('individuals', 0.623636263505841), ('have', 0.6067177331389374), ('Manufactured Object,Organization', 0.5972446385954493), ('Phenomenon or Process', 0.59109440226243304), ('lab', 0.56844390438838543), ('Manufactured Object', 0.56699581871726945), ('had', 0.54631280132697513), ('least', 0.54388464067520093)]\n",
      "f1 score 0.5\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[2, 0, 34, 4]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('_number_', 1.4327436935478064), ('Quantitative Concept', 0.84977856916402716), ('more', 0.83509585818954535), ('Classification', 0.77527681974213514), ('Disease or Syndrome', 0.7571967734612951), ('occasions', 0.68961030776924781), ('abnormal', 0.64582590835788167), ('visits', 0.60114935105812062), ('having', 0.55607180677245749), ('diagnoses', 0.54078034007549003), ('medication', 0.5286285427502827), ('ge', 0.51243775612059239), ('icd9', 0.50486151029521265), ('above', 0.4992542518525544), ('apart', 0.4887586398327789), ('occur', 0.46838489944500433), ('successive', 0.46838489944500433), ('Activity', 0.46105957521478791), ('relevant', 0.45155671953968718), ('classes', 0.42959062325676656)]\n",
      "f1 score 0.740740740741\n",
      "predicted label [0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[10, 1, 23, 6]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('months', 5.6763314241663485), ('days', 5.0514719802620558), ('0.5', 3.4754101626133806), ('separated', 3.282968839897983), ('distinct', 3.1852919660808441), ('occasions', 2.9032982397293403), ('dates', 2.795903342403895), ('most', 2.5956703208137202), ('chf', 2.2626416409922521), ('apart', 2.256542661924116), ('supplies', 1.4238646123207772), ('relevant', 1.3909991749876796), ('_number_', 0.99585322240692709), ('mg', 0.97155973338808288), ('different', 0.74789391025286023), ('subject', 0.69673940972624326), ('measurements', 0.67721827673762114), ('code', 0.49760053279860827), ('Qualitative Concept', 0.22493571071738483), ('Finding', 0.22174000087881796)]\n",
      "f1 score 0.823529411765\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[7, 0, 30, 3]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('Professional or Occupational Group', 0.54499442576624979), ('Biomedical Occupation or Discipline', 0.4554992450202448), ('ophthalmology', 0.43278870721519147), ('optometry', 0.43278870721519147), ('clinical', 0.36463818884972926), ('Organization', 0.32687189314578752), ('above', 0.30409173003597406), ('within', 0.30168026135811776), ('provider', 0.29994354486571823), ('department', 0.29720254085825387), ('see', 0.2922696556665097), ('select', 0.27948879556783024), ('having', 0.2787041544649928), ('diagnoses', 0.26981014680724985), ('diagnosis', 0.26529997880553946), ('subjects', 0.24892276319457984), ('psychology', 0.23718577678059391), ('providers', 0.22996925001263091), ('following', 0.22265105839144309), ('from', 0.20814498177914814)]\n",
      "f1 score 1.0\n",
      "predicted label [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 0, 36, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('Patient or Disabled Group', 1.5508703300919311), ('outpatient', 0.95515591533547173), ('hospital', 0.93988674286099272), ('discharge', 0.79294690515805755), ('inpatient', 0.64191610315624792), ('meeting', 0.62327833300617153), ('mrsa', 0.60981919244176264), ('after', 0.59341872970326803), ('considering', 0.59181710329653947), ('year', 0.58202048463042844), ('during', 0.5556943575044615), ('Gene or Genome', 0.55301692278046366), ('Body Substance', 0.54416395445517973), ('admission', 0.53560047540273437), ('Health Care Related Organization,Manufactured Object', 0.52410574093717655), ('possible', 0.51603222600467724), ('hospitalization', 0.50578870275003718), ('Bacterium', 0.4999589414062468), ('stay', 0.47203520021039536), ('keep', 0.47203520021039536)]\n",
      "f1 score 0.714285714286\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0\n",
      " 1 0 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[5, 2, 31, 2]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('Organism Function', 1.1027147743970567), ('negative', 1.0975740452856433), ('terms', 1.0191713034154517), ('negated', 0.93213182089077318), ('appendicitis', 0.81211615091046085), ('reported', 0.81211615091046085), ('mention', 0.79705404033318028), ('evidence', 0.71829846172488199), ('history', 0.65596913261421053), ('no', 0.6067093706651171), ('family', 0.56569763925125038), ('Idea or Concept', 0.55857567183178825), ('section', 0.53732446379540622), ('Disease or Syndrome', 0.53148380712201992), ('probable', 0.51048493347104573), ('diabetic', 0.50896808649429726), ('dt', 0.5035972405536403), ('cnt', 0.5035972405536403), ('pt', 0.5035972405536403), ('t1dm', 0.5035972405536403)]\n",
      "f1 score 0.833333333333\n",
      "predicted label [0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[5, 1, 33, 1]\n",
      "[0.5, 0.74074074074074059, 0.82352941176470584, 1.0, 0.7142857142857143, 0.83333333333333337]\n",
      "macro_f1:  0.7917301130398808\n",
      "micro_f1:  0.7674418604651163\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test_fit))\n",
    "print(len(all_test_st))\n",
    "x_train_st,x_test_st,features_st = addmatrix(x_train_fit,all_train_st,features,st,x_test_fit,all_test_st)\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_st, x_test_st,patternlist_train[i],patternlist_test[i],features_st)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset_mem = subset(embedding_word,features,mem)\n",
    "subset_mem = np.zeros((len(features), 200))\n",
    "(mem, hwoov, hwid) = a\n",
    "for i in range(len(features)):\n",
    "    try:\n",
    "        subset_mem[i,:] = mem[hwid[str.encode(features[i])],:]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOcc_train = findOccurance(train_text,\"_number_\")         \n",
    "numberOcc_test = findOccurance(test_text,\"_number_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(14, 3.9798324648882542), (82, 3.6273838844771955), (113, 3.5778733624142665), (22, 3.3774837434625216), (43, 3.190971797918944), (69, 2.3538445056901081), (160, 2.2719328450034988), (179, 2.1164473309825116), (45, 2.0098076887361964), (84, 1.7236222566188382), (154, 1.7134027638157086), (145, 1.4136668527605356), (148, 1.3623364338867414), (109, 1.2516572310218996), (102, 0.98985941381665754), (11, 0.92829514344200859), (55, 0.88009945280962376), (17, 0.75836894274068722), (155, 0.75149827218181986), (170, 0.46809340222642665)]\n",
      "f1 score 0.307692307692\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1\n",
      " 0 0 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[2, 5, 29, 4]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(100, 0.23322457448778006), (155, 0.2148899165037664), (127, 0.21260156158306362), (168, 0.21129476093996474), (184, 0.19465374026601773), (51, 0.18736527605754313), (187, 0.18065972896022225), (8, 0.17858097976383266), (170, 0.17694028400711656), (188, 0.17638332805720852), (9, 0.17396887434131539), (40, 0.16767947194997918), (186, 0.16693499800217207), (24, 0.16660915618494357), (83, 0.15450771535643823), (5, 0.15405988313774058), (38, 0.1525910322284337), (189, 0.15016288542932291), (33, 0.1496615260636267), (98, 0.147559163974473)]\n",
      "f1 score 0.666666666667\n",
      "predicted label [0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[9, 2, 22, 7]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(91, 5.6294239405818356), (8, 5.1357774456449921), (138, 4.4842658702003888), (39, 3.3656108664753002), (19, 3.0977948844172469), (198, 3.0840161188172845), (169, 2.8317343051575912), (127, 2.4277540859415536), (84, 1.8565388990235445), (193, 1.548812709484648), (119, 1.4283751537642626), (189, 1.2431858143442587), (41, 1.1959462360886561), (51, 1.0531734648932927), (134, 1.0285435899230817), (190, 0.7403741674496962), (177, 0.56647745003137262), (146, 0.37567696546886037), (174, 0.26789548402970209), (36, 0.139606865603779)]\n",
      "f1 score 0.434782608696\n",
      "predicted label [0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[5, 8, 22, 5]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(148, 7.7405528201854104), (106, 5.6739830746971816), (49, 4.603637737368194), (120, 3.2009298592575348), (56, 2.9718799586063804), (151, 2.7986059786921724), (184, 2.098423048914464), (12, 2.078295326182849), (18, 1.7213825158239116), (23, 1.711668465874687), (3, 1.278143837303058), (123, 1.1589373390825837), (1, 1.0295845777699255), (199, 0.90899626265453293), (196, 0.83455848927117482), (112, 0.78858005066071335), (188, 0.67474400580807414), (117, 0.66020744964333522), (116, 0.29344534490316126), (174, -0.048768598699154314)]\n",
      "f1 score 0.571428571429\n",
      "predicted label [0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 6, 30, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(105, 6.3564413321383284e-06), (90, 6.1269916916940601e-06), (46, 5.2557628400626834e-06), (50, 5.2279738993091738e-06), (109, 5.0016068486592618e-06), (175, 4.9705708089789036e-06), (52, 4.8441932742393309e-06), (178, 4.6557266234152476e-06), (42, 4.3481041284725314e-06), (104, 4.142486455295054e-06), (166, 4.035400493987069e-06), (17, 3.9931113460647762e-06), (177, 3.9459174847235941e-06), (136, 3.7879193008060348e-06), (115, 3.6111583355385025e-06), (125, 3.4951943103642194e-06), (70, 3.4492434251358385e-06), (93, 3.407764848303465e-06), (91, 3.3313588300445268e-06), (78, 3.2433819311856437e-06)]\n",
      "f1 score 0.48\n",
      "predicted label [0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 0 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[6, 12, 21, 1]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('number', 1.5502430491486464e-05), (176, 4.8443325530834634e-06), (29, 4.7517115847500818e-06), (113, 4.7268156877396623e-06), (187, 4.5840301888482708e-06), (180, 4.5383164328262702e-06), (110, 3.9848768750168168e-06), (192, 3.7693493100445704e-06), (22, 3.744797165242959e-06), (62, 3.4131399644911344e-06), (58, 3.3444778592247239e-06), (183, 3.3263520730228582e-06), (13, 3.2820308539112695e-06), (59, 3.2751521329010783e-06), (143, 3.2522608191858632e-06), (31, 3.2131458091366881e-06), (28, 3.151541635273361e-06), (107, 3.0902825677782804e-06), (99, 3.0361052828827078e-06), (26, 3.003710938851126e-06)]\n",
      "f1 score 0.428571428571\n",
      "predicted label [1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1\n",
      " 0 1 1]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[6, 16, 18, 0]\n",
      "[0.30769230769230765, 0.66666666666666663, 0.43478260869565222, 0.57142857142857151, 0.47999999999999998, 0.42857142857142855]\n",
      "macro_f1:  0.5241091665422848\n",
      "micro_f1:  0.49230769230769234\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_embedding,x_test_embedding,feature_embedding = embedding(x_train_fit,x_test_fit,numberOcc_train,numberOcc_test,subset_mem)\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_embedding, x_test_embedding,patternlist_train[i],patternlist_test[i],feature_embedding)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(43, 2.563599657849299), (79, 1.6062913941967949), (14, 1.3916277156716683), (110, 0.9228269090817558), (23, 0.67734858360218542), ('Mount Sinai', 0.30979180265900325), (45, 0.26188876932881322), ('number', 0.22662914133283155), (90, 0.17099841924029435), (145, 0.092987826345458685), ('Marshfield', 0.049455814932837745), ('Mayo', -0.18364267574404894), (174, -0.26997374982293371), ('Group Health', -0.33503628645050465), (123, -0.40735299446594991), (19, -1.1148570225724683), (193, -1.5037612046354047), (67, -1.8565070154855512), (51, -2.0344420118789954), (127, -2.3457548685816376)]\n",
      "f1 score 0.428571428571\n",
      "predicted label [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1\n",
      " 0 1 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[3, 5, 29, 3]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(100, 1.0351676062031849), (184, 0.92409079191275501), (40, 0.80934076369708807), (127, 0.78175142650766594), (186, 0.73352470798578628), (8, 0.71731105913990756), (9, 0.69455606723087604), (170, 0.69278119140327243), (124, 0.66936941018851015), (188, 0.66923114891372304), (63, 0.66283708715177325), (189, 0.66208707825883473), (155, 0.65518410611535738), (168, 0.61815437142783469), (123, 0.59587455108301046), (121, 0.59400908041000833), (51, 0.59195413778599237), (24, 0.58133773022741608), (156, 0.54681608565206619), (38, 0.53474952767670281)]\n",
      "f1 score 0.592592592593\n",
      "predicted label [0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[8, 3, 21, 8]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(138, 6.9102594623168025), (8, 5.6295403712168), (189, 4.5597883233794549), (127, 4.54489379488703), (72, 3.2291313280664866), (91, 3.1702719109908424), (134, 3.0563327567590912), (84, 2.6646012289731784), (119, 2.3581775308062878), (160, 2.2802477791666833), (19, 1.8400027056651886), (198, 1.2915441826062888), (71, 1.2411933882282415), ('Northwestern', 0.98792756778761426), (39, 0.94366200198787431), (164, 0.82446596468735445), (1, 0.36815812999346115), (144, -0.0077608555611198291), ('Vanderbilt', -0.24467236327210587), ('Mayo', -0.24470472173868604)]\n",
      "f1 score 0.380952380952\n",
      "predicted label [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 7, 23, 6]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(148, 0.89995615358791203), (151, 0.72467974165395421), (49, 0.71147782632825463), (199, 0.70185789787082098), (120, 0.69210707738572208), (12, 0.66868471043219313), (106, 0.62821659336090074), (100, 0.62125333507804414), ('Mount Sinai', 0.60326938193373647), (117, 0.5771080767977439), (116, 0.56275149656496148), (133, 0.55812385635121298), (81, 0.52160744774007184), (6, 0.49842240885012645), (15, 0.4772244399579238), (122, 0.44020128409544945), (69, 0.43552312611613292), (1, 0.42473879593376218), (138, 0.4215546038559902), (71, 0.41920944394099596)]\n",
      "f1 score 0.666666666667\n",
      "predicted label [0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 4, 32, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(105, 0.89503570439971447), (191, 0.86684938861113425), (178, 0.86245372928045161), (104, 0.7558955225778442), (175, 0.75504742949554338), (90, 0.72513290122849838), (129, 0.71406735006135136), (17, 0.63172314930516116), (46, 0.61273081896749082), (50, 0.58953060832626736), (115, 0.58797811515720144), (56, 0.58540818168209663), (130, 0.57750104029133453), (42, 0.5672702245207244), (89, 0.5448636341887233), (52, 0.53143385985905878), (152, 0.52816735670851178), (197, 0.50027776000303692), (93, 0.49011260341722829), (125, 0.48677126877943183)]\n",
      "f1 score 0.428571428571\n",
      "predicted label [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0\n",
      " 0 0 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[3, 4, 29, 4]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('number', 0.50442232652282559), ('Vanderbilt', 0.33388706501483667), ('CCHMC', 0.26902255877190318), (176, 0.2597760874384461), (29, 0.22690712135906682), (187, 0.22385213051758279), (192, 0.21909600535348298), (180, 0.21669885330297711), (22, 0.21537240294499665), (62, 0.20575992420334208), ('Geisinger', 0.19804963384831911), (110, 0.1955648350164878), (113, 0.19444286762836999), (13, 0.18128351125923287), (69, 0.18099677427467295), (58, 0.17962393951298972), (28, 0.17945085773915853), (143, 0.17712275622528789), (108, 0.17514536091413693), (54, 0.17440763002452864)]\n",
      "f1 score 0.666666666667\n",
      "predicted label [1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[5, 4, 30, 1]\n",
      "[0.42857142857142855, 0.59259259259259256, 0.38095238095238099, 0.66666666666666663, 0.42857142857142855, 0.66666666666666674]\n",
      "macro_f1:  0.544608177708356\n",
      "micro_f1:  0.5242718446601942\n"
     ]
    }
   ],
   "source": [
    "x_train_em_site,x_test_em_site,feature_em_site = addmatrix(x_train_embedding,all_train_site,feature_embedding,site_category,x_test_embedding,all_test_site)\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_em_site, x_test_em_site,patternlist_train[i],patternlist_test[i],feature_em_site)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(14, 3.9798324648882542), (82, 3.6273838844771955), (113, 3.5778733624142665), (22, 3.3774837434625216), (43, 3.190971797918944), (69, 2.3538445056901081), (160, 2.2719328450034988), (179, 2.1164473309825116), (45, 2.0098076887361964), (84, 1.7236222566188382), (154, 1.7134027638157086), (145, 1.4136668527605356), (148, 1.3623364338867414), (109, 1.2516572310218996), (102, 0.98985941381665754), (11, 0.92829514344200859), (55, 0.88009945280962376), (17, 0.75836894274068722), (155, 0.75149827218181986), (170, 0.46809340222642665)]\n",
      "f1 score 0.307692307692\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1\n",
      " 0 0 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[2, 5, 29, 4]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(100, 0.23322457448778006), (155, 0.2148899165037664), (127, 0.21260156158306362), (168, 0.21129476093996474), (184, 0.19465374026601773), (51, 0.18736527605754313), (187, 0.18065972896022225), (8, 0.17858097976383266), (170, 0.17694028400711656), (188, 0.17638332805720852), (9, 0.17396887434131539), (40, 0.16767947194997918), (186, 0.16693499800217207), (24, 0.16660915618494357), (83, 0.15450771535643823), (5, 0.15405988313774058), (38, 0.1525910322284337), (189, 0.15016288542932291), (33, 0.1496615260636267), (98, 0.147559163974473)]\n",
      "f1 score 0.666666666667\n",
      "predicted label [0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[9, 2, 22, 7]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(91, 5.6294239405818356), (8, 5.1357774456449921), (138, 4.4842658702003888), (39, 3.3656108664753002), (19, 3.0977948844172469), (198, 3.0840161188172845), (169, 2.8317343051575912), (127, 2.4277540859415536), (84, 1.8565388990235445), (193, 1.548812709484648), (119, 1.4283751537642626), (189, 1.2431858143442587), (41, 1.1959462360886561), (51, 1.0531734648932927), (134, 1.0285435899230817), (190, 0.7403741674496962), (177, 0.56647745003137262), (146, 0.37567696546886037), (174, 0.26789548402970209), (36, 0.139606865603779)]\n",
      "f1 score 0.434782608696\n",
      "predicted label [0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[5, 8, 22, 5]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(148, 7.7405528201854104), (106, 5.6739830746971816), (49, 4.603637737368194), (120, 3.2009298592575348), (56, 2.9718799586063804), (151, 2.7986059786921724), (184, 2.098423048914464), (12, 2.078295326182849), (18, 1.7213825158239116), (23, 1.711668465874687), (3, 1.278143837303058), (123, 1.1589373390825837), (1, 1.0295845777699255), (199, 0.90899626265453293), (196, 0.83455848927117482), (112, 0.78858005066071335), (188, 0.67474400580807414), (117, 0.66020744964333522), (116, 0.29344534490316126), (174, -0.048768598699154314)]\n",
      "f1 score 0.571428571429\n",
      "predicted label [0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 6, 30, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[(105, 6.3564413321383284e-06), (90, 6.1269916916940601e-06), (46, 5.2557628400626834e-06), (50, 5.2279738993091738e-06), (109, 5.0016068486592618e-06), (175, 4.9705708089789036e-06), (52, 4.8441932742393309e-06), (178, 4.6557266234152476e-06), (42, 4.3481041284725314e-06), (104, 4.142486455295054e-06), (166, 4.035400493987069e-06), (17, 3.9931113460647762e-06), (177, 3.9459174847235941e-06), (136, 3.7879193008060348e-06), (115, 3.6111583355385025e-06), (125, 3.4951943103642194e-06), (70, 3.4492434251358385e-06), (93, 3.407764848303465e-06), (91, 3.3313588300445268e-06), (78, 3.2433819311856437e-06)]\n",
      "f1 score 0.48\n",
      "predicted label [0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 0 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[6, 12, 21, 1]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('number', 1.5502430491486464e-05), (176, 4.8443325530834634e-06), (29, 4.7517115847500818e-06), (113, 4.7268156877396623e-06), (187, 4.5840301888482708e-06), (180, 4.5383164328262702e-06), (110, 3.9848768750168168e-06), (192, 3.7693493100445704e-06), (22, 3.744797165242959e-06), (62, 3.4131399644911344e-06), (58, 3.3444778592247239e-06), (183, 3.3263520730228582e-06), (13, 3.2820308539112695e-06), (59, 3.2751521329010783e-06), (143, 3.2522608191858632e-06), (31, 3.2131458091366881e-06), (28, 3.151541635273361e-06), (107, 3.0902825677782804e-06), (99, 3.0361052828827078e-06), (26, 3.003710938851126e-06)]\n",
      "f1 score 0.428571428571\n",
      "predicted label [1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1\n",
      " 0 1 1]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[6, 16, 18, 0]\n",
      "[0.30769230769230765, 0.66666666666666663, 0.43478260869565222, 0.57142857142857151, 0.47999999999999998, 0.42857142857142855]\n",
      "macro_f1:  0.5241091665422848\n",
      "micro_f1:  0.49230769230769234\n"
     ]
    }
   ],
   "source": [
    "x_train_em_algo,x_test_em_algo,feature_em_algo = addmatrix(x_train_embedding,all_train_algo,feature_embedding,algo_category,x_test_embedding,all_test_algo)\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_embedding, x_test_embedding,patternlist_train[i],patternlist_test[i],feature_embedding)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('C0200149', 1.0339240498137716), ('C1316572', 0.70197469683893221), ('C1317574', 0.6498745293919227), ('C1707391', 0.64436448503937316), ('C0242485', 0.63366626033871154), ('C0205447', 0.62045482063013424), (79, 0.54724589518899069), ('C0220908', 0.51540720280583507), ('C1305399', 0.51540720280583507), ('C1705053', 0.51540720280583507), (110, 0.5047833574815116), ('C1274040', 0.49376392840008959), ('C1546471', 0.49376392840008959), ('C2825142', 0.49376392840008959), ('C3539897', 0.47048371541957917), (179, 0.44413904322350306), ('C1623258', 0.44250878019701889), ('C0547044', 0.43364007916474168), ('C0439092', 0.43364007916474168), (154, 0.42803247047221554)]\n",
      "f1 score 0.25\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[1, 1, 33, 5]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('C0205448', 1.4154626102903183), ('C0205172', 0.92085017091308241), ('C3897109', 0.88000312799792335), ('C0011900', 0.86379819070784658), ('C0450371', 0.72315531286771384), ('C3244316', 0.69830821450293945), ('C0042789', 0.67254402632175569), ('C1947903', 0.67254402632175569), (123, 0.60272498852562495), (121, 0.60100891859723748), ('C3244320', 0.59880306696143037), ('C1706214', 0.59880306696143037), ('C0019693', 0.5880342298296346), (184, 0.58497503119701422), ('C2826704', 0.54466921032629478), ('C0521114', 0.54253903193503983), (186, 0.52972764670564587), (40, 0.52545222214343879), ('C1279901', 0.51450460128518505), ('C0205435', 0.51450460128518505)]\n",
      "f1 score 0.785714285714\n",
      "predicted label [0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[11, 1, 23, 5]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('C0205448', 2.4650070695078807), ('C3897109', 1.340781730268314), ('C1547564', 1.0457959471055132), ('C0521114', 0.8769509801463119), (138, 0.77792286130830179), ('C0018802', 0.75115902863105011), ('number', 0.74912580823694364), ('C1550213', 0.74586227270172656), ('C0443299', 0.7371910764662416), ('C0750480', 0.71183887441868521), ('C1705566', 0.71183887441868521), (84, 0.70356055526401218), (51, 0.6995093010020409), ('C1551058', 0.68741648483876627), (8, 0.68034313792755174), ('C0547044', 0.66810178159707134), ('C0439092', 0.66810178159707134), ('C3244320', 0.65531721039476909), ('C1706214', 0.65531721039476909), (39, 0.64745895132217068)]\n",
      "f1 score 0.3\n",
      "predicted label [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 1 0 0]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[3, 7, 23, 7]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('C1704729', 0.33800798776876229), ('C0011900', 0.33685910612304748), ('C1138603', 0.30176343072598144), ('C0919279', 0.26901005082408175), (199, 0.25942535054062155), (148, 0.25334795394666731), ('C3871137', 0.24383716603474553), ('C1704656', 0.22624604581865543), ('C1704338', 0.22624604581865543), ('C0237412', 0.20120292166219028), ('C0497591', 0.20120292166219028), ('C0205210', 0.20120292166219028), ('C1553058', 0.20120292166219028), (120, 0.19703414877339664), (6, 0.18778461510113192), ('C0332196', 0.18005131557184578), ('C0205451', 0.17898868758604261), (133, 0.17100986584429576), ('C0029147', 0.16130424174024766), ('C0587524', 0.16130424174024766)]\n",
      "f1 score 0.727272727273\n",
      "predicted label [0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 3, 33, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('C0021562', 0.84291939586557041), ('C1548439', 0.75660862001990015), ('C1549405', 0.75660862001990015), ('C0029921', 0.75660862001990015), ('C1548438', 0.60233163444432025), ('C1549404', 0.60233163444432025), ('C0456393', 0.47593906885293574), ('C0333118', 0.47593906885293574), ('C0750591', 0.42180501050551089), ('C3715113', 0.41937552963939939), ('C0012621', 0.41448918194858114), ('C0030685', 0.41448918194858114), ('C2926602', 0.41448918194858114), (105, 0.40176291985532714), (178, 0.3959515830844198), (90, 0.3607367684841663), ('C0439508', 0.35336724281107984), ('C1265292', 0.34804805500164537), ('C3810814', 0.33800778376605367), ('C0070166', 0.33800778376605367)]\n",
      "f1 score 0.714285714286\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0\n",
      " 1 0 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[5, 2, 31, 2]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('C1518422', 1.638975221949148e-05), ('number', 1.5502106877369915e-05), ('C1705313', 8.7396961313193678e-06), ('C0233324', 6.9310105895754754e-06), ('C1515273', 6.9310105895754754e-06), ('C2826302', 6.9310105895754754e-06), (176, 4.8442725031996078e-06), (29, 4.75164389400898e-06), (113, 4.7267780296578338e-06), (187, 4.583934949810657e-06), (180, 4.5383072229917438e-06), (110, 3.984836670865897e-06), (192, 3.769316807938696e-06), (22, 3.7447693160033583e-06), ('C0684224', 3.5025218014056679e-06), ('C0455547', 3.5025218014056679e-06), ('C0700287', 3.5025218014056679e-06), (62, 3.4131333414723819e-06), (58, 3.3444577849694949e-06), (183, 3.3263487933225841e-06)]\n",
      "f1 score 0.444444444444\n",
      "predicted label [1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1\n",
      " 0 1 1]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[6, 15, 19, 0]\n",
      "[0.25, 0.7857142857142857, 0.29999999999999999, 0.72727272727272729, 0.7142857142857143, 0.44444444444444448]\n",
      "macro_f1:  0.5924569839025465\n",
      "micro_f1:  0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "x_train_em_cui, x_test_em_cui, feature_em_cui = addmatrix(x_train_embedding,all_train_CUI,feature_embedding,CUI,x_test_embedding,all_test_CUI)\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_em_cui, x_test_em_cui,patternlist_train[i],patternlist_test[i],feature_em_cui)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "classification: Confirm Disease Was Checked\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('Diagnostic Procedure', 4.7628312351476447), (79, 4.2537568024006891), ('Human', 2.9855231156055675), (154, 2.7241046741887267), (43, 2.7113570807930936), ('Clinical Attribute', 1.6862546467859423), (110, 0.93963788293936457), ('Therapeutic or Preventive Procedure', 0.92621568761393358), (160, 0.89891744365758852), (100, 0.72844184746151608), ('Manufactured Object', 0.71739871975843317), (149, 0.69560802357624119), (108, 0.64399666285715274), (76, 0.46801869280022268), ('Occupational Activity', 0.45584895297957101), (113, 0.39543836161738166), ('number', 0.36403725903423351), ('Biomedical Occupation or Discipline', -0.14068996291997357), (6, -0.17813105657737527), (98, -0.20949549987529398)]\n",
      "f1 score 0.0\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0]\n",
      "true label [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[0, 2, 32, 6]\n",
      "########################################\n",
      "classification: Rule of N\n",
      "number of training sentences: 33\n",
      "number of testing sentences: 16\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('Quantitative Concept', 0.10072955429959769), ('Classification', 0.063098015762143883), ('Disease or Syndrome', 0.040196857057075389), ('Behavior', 0.029646603572695648), (100, 0.029630220551366201), ('Occupational Activity', 0.028807712125411947), (155, 0.02734134077378229), (127, 0.027038228812153085), (168, 0.026607056941970856), (51, 0.024962105353690939), (184, 0.024258441424358974), (5, 0.024029886565211211), ('Activity', 0.023851273631204983), (83, 0.023619149632282104), (8, 0.023523223706849877), (170, 0.023090089305135956), (188, 0.022627370721272043), (187, 0.021911419456727994), ('Finding', 0.02158120939967844), (24, 0.02098761912247667)]\n",
      "f1 score 0.666666666667\n",
      "predicted label [0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[9, 2, 22, 7]\n",
      "########################################\n",
      "classification: Use Distinct Dates\n",
      "number of training sentences: 26\n",
      "number of testing sentences: 10\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('Temporal Concept', 1.4900400003173386e-05), ('Quantitative Concept', 1.1011575757887883e-05), ('Qualitative Concept', 7.3819132063015694e-06), ('Behavior', 5.4921323576490727e-06), ('Finding', 4.4549202681200802e-06), (39, 4.1108846905983196e-06), (5, 3.7851450660584599e-06), (8, 3.7611674690013571e-06), (138, 3.5274261933551041e-06), (83, 3.3512056240827482e-06), (9, 3.2704694324888841e-06), (146, 2.9981156275794156e-06), (51, 2.9001049483512211e-06), (189, 2.8395090296994439e-06), (134, 2.8340875924256938e-06), ('Food', 2.5990863369851724e-06), (127, 2.4805707222308774e-06), (91, 2.447751833150767e-06), (195, 2.4086584817881468e-06), (71, 2.4063876701070399e-06)]\n",
      "f1 score 0.387096774194\n",
      "predicted label [1 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 1\n",
      " 1 1 1]\n",
      "true label [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[6, 15, 15, 4]\n",
      "########################################\n",
      "classification: Credentials of the Actor\n",
      "number of training sentences: 13\n",
      "number of testing sentences: 4\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('Professional or Occupational Group', 1.5035429440559975), (148, 1.2962593604646231), ('Organization', 1.0482946776137454), ('Biomedical Occupation or Discipline', 1.0203314163905994), (120, 0.96324034032872285), (106, 0.87563674270242187), ('Research Activity', 0.87310114172316489), ('Spatial Concept', 0.85678053129333187), (112, 0.84889436714855715), (133, 0.81302747490039562), (73, 0.81117516243075594), ('Occupational Activity', 0.7975218719078575), (81, 0.78420118358606705), (143, 0.77179161302095212), (23, 0.74884501255402536), (199, 0.73391247371046331), ('Amino Acid, Peptide, or Protein,Biologically Active Substance', 0.72170974389802689), (49, 0.71816245809135648), (18, 0.68909982637038691), (0, 0.66498774677156747)]\n",
      "f1 score 0.727272727273\n",
      "predicted label [0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "true label [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "__________________________________________________\n",
      "[4, 3, 33, 0]\n",
      "########################################\n",
      "classification: Where Did It Happen?\n",
      "number of training sentences: 12\n",
      "number of testing sentences: 7\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('Patient or Disabled Group', 1.8646186298224479), ('Body Substance', 0.65524736939110528), ('Bacterium', 0.57727797300207662), ('Gene or Genome', 0.56013039248868313), (105, 0.52463222467415727), ('Idea or Concept', 0.5212237818821166), (178, 0.50859578840498021), (104, 0.48584171342644139), (152, 0.48374332798627551), (129, 0.47681232735629064), (52, 0.45453751883062443), ('Laboratory Procedure', 0.45253142223295384), (175, 0.44926291229457438), (17, 0.44271771954870798), (90, 0.43346255567031938), (50, 0.42783727436419244), (191, 0.39457766976920866), (115, 0.37122551080251631), (56, 0.33397208650109189), ('Diagnostic Procedure', 0.32304080789333917)]\n",
      "f1 score 0.615384615385\n",
      "predicted label [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 1]\n",
      "true label [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "__________________________________________________\n",
      "[4, 2, 31, 3]\n",
      "########################################\n",
      "classification: Check For Negation\n",
      "number of training sentences: 15\n",
      "number of testing sentences: 6\n",
      "option: BOW\n",
      "\n",
      "\n",
      "rank feature in decreasing order:\n",
      "[('number', 0.48618080032345057), ('Organism Function', 0.48090587964601117), ('Idea or Concept', 0.3025967475538559), ('Disease or Syndrome', 0.27814494093503733), ('Intellectual Product', 0.2508893044729541), ('Therapeutic or Preventive Procedure', 0.24934831071387578), (187, 0.22913999025849915), (29, 0.22849024745355401), (176, 0.22489278782417929), (113, 0.22083696166518563), (110, 0.20506404754339827), (143, 0.20439055131073536), (192, 0.19802460705829916), ('Gene or Genome', 0.1940308808960492), (58, 0.19390787410141477), (180, 0.19328917936096759), (69, 0.1908658887985917), (28, 0.18133930206749049), (22, 0.18077684205558503), (62, 0.17321605544308166)]\n",
      "f1 score 0.588235294118\n",
      "predicted label [1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0]\n",
      "true label [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "__________________________________________________\n",
      "[5, 6, 28, 1]\n",
      "[0.0, 0.66666666666666663, 0.38709677419354832, 0.72727272727272729, 0.61538461538461531, 0.58823529411764708]\n",
      "macro_f1:  0.522537960307405\n",
      "micro_f1:  0.5233644859813084\n"
     ]
    }
   ],
   "source": [
    "x_train_em_st, x_test_em_st, feature_em_st = addmatrix(x_train_embedding,all_train_st,feature_embedding,st,x_test_embedding,all_test_st)\n",
    "\n",
    "count_base = []\n",
    "f1 = []\n",
    "for i in range(len(name)):\n",
    "    print(\"#\"*40)\n",
    "\n",
    "    print(\"classification:\",name[i]) \n",
    "\n",
    "    print(\"number of training sentences:\", patternlist_train[i].count(1))\n",
    "    print(\"number of testing sentences:\", patternlist_test[i].count(1))\n",
    "    print(\"option: BOW\")\n",
    "\n",
    "    base,f1_class = prediction(x_train_em_st, x_test_em_st,patternlist_train[i],patternlist_test[i],feature_em_st)\n",
    "    print(base)\n",
    "    count_base.append(base) \n",
    "    f1.append(f1_class)\n",
    "print(f1)\n",
    "print(\"macro_f1: \", count_f1(count_base)[0])\n",
    "print(\"micro_f1: \", count_f1(count_base)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
